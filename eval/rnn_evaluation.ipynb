{"cells":[{"cell_type":"markdown","metadata":{},"source":["# RNN Model Evaluation\n","This notebook evaluates the performance of the RNN model in predicting the time an item will be on sale, using sample data as input."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cpu\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import pandas as pd\n","from sklearn.metrics import mean_absolute_error\n","from tqdm import tqdm\n","from datetime import datetime\n","import os\n","\n","pd.options.display.max_columns = None\n","pd.options.display.width = None\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Load and Preprocess Data"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Items shape: (5569, 13)\n","Number of unique items: 5569\n"]}],"source":["\n","items = pd.read_csv('../data/items.csv')\n","print(\"Items shape:\", items.shape)\n","n_items = len(items)\n","item_to_index = {item_id: i + 2 for i, item_id in enumerate(items['item_id'])}\n","item_to_index[0] = 0 \n","item_to_index[1] = 1  \n","print(f\"Number of unique items: {n_items}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Data Preprocessing"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","\n","class Encoder(nn.Module):\n","    def __init__(self, input_size=5, item_index=3, embedding_size=16, hidden_size=16, dropout_p=0.1, bidirectional=True):\n","        super(Encoder, self).__init__()\n","\n","        self.hidden_size = hidden_size\n","        self.item_index = item_index\n","        n_items = len(item_to_index)\n","\n","        self.embedding = nn.Embedding(n_items, embedding_size)\n","        self.rnn = nn.LSTM(input_size + embedding_size, hidden_size, batch_first=True, num_layers=2, bidirectional=bidirectional)\n","        self.dropout = nn.Dropout(dropout_p)\n","\n","    def forward(self, X):\n","        item_ids = X[:, :, self.item_index].long()\n","\n","        X = torch.cat([X[:, :, :self.item_index], X[:, :, self.item_index + 1:]], dim=2)\n","\n","        item_embeddings = self.dropout(self.embedding(item_ids))\n","\n","        X = torch.cat([X, item_embeddings], dim=2)\n","\n","        output, (hidden, cell) = self.rnn(X)\n","\n","        return output, (hidden, cell)\n","\n","class Decoder(nn.Module):\n","    def __init__(self, input_size, hidden_size, bidirectional=True):\n","        super(Decoder, self).__init__()\n","        output_size = hidden_size * 2 if bidirectional else hidden_size\n","        self.rnn = nn.LSTM(input_size, hidden_size, batch_first=True, num_layers=2, bidirectional=bidirectional)\n","        self.projection = nn.Sequential(\n","            nn.Linear(output_size, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, 32),\n","            nn.ReLU(),\n","            nn.Linear(32, 1)\n","        )\n","\n","    def forward(self, encoder_outputs, encoder_hidden):\n","        output, _ = self.rnn(encoder_outputs, encoder_hidden)\n","        output = self.projection(output)\n","        return output\n","\n","class AuctionPredictor(nn.Module):\n","    def __init__(self, input_size=5, encoder_hidden_size=16, decoder_hidden_size=16, item_index=3, embedding_size=16, dropout_p=0.1, bidirectional=True):\n","        super(AuctionPredictor, self).__init__()\n","        decoder_input_size = encoder_hidden_size * 2 if bidirectional else encoder_hidden_size\n","        self.encoder = Encoder(input_size, item_index, embedding_size, encoder_hidden_size, dropout_p, bidirectional=bidirectional)\n","        self.decoder = Decoder(decoder_input_size, decoder_hidden_size, bidirectional=bidirectional)\n","\n","    def forward(self, X):\n","        encoder_outputs, encoder_hidden = self.encoder(X)\n","        decoder_outputs = self.decoder(encoder_outputs, encoder_hidden)\n","        return decoder_outputs"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Historical prices loaded successfully.\n"]}],"source":["\n","historical_prices_path = '../data/historical_prices.csv'\n","if not os.path.exists(historical_prices_path):\n","    historical_prices_path = 'historical_prices.csv'\n","\n","try:\n","\n","    weekly_historical_prices = pd.read_csv(historical_prices_path)\n","    weekly_historical_prices['datetime'] = weekly_historical_prices['datetime'].astype(str)\n","    weekly_historical_prices.set_index(['item_id', 'datetime'], inplace=True)\n","    \n","    print('Historical prices loaded successfully.')\n","except FileNotFoundError:\n","    print(f'Error: The historical prices file {historical_prices_path} was not found.')\n","    weekly_historical_prices = pd.DataFrame(columns=['item_id', 'datetime', 'price'])"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["class AuctionDataset(torch.utils.data.Dataset):\n","    def __init__(self, sample_data_path, item_to_index, weekly_historical_prices):\n","        self.sample_data_path = sample_data_path\n","        self.item_to_index = item_to_index\n","        self.weekly_historical_prices = weekly_historical_prices\n","        self.sample_dates = os.listdir(sample_data_path)\n","        self.sample_hours = []\n","        for date in self.sample_dates:\n","            self.sample_hours.extend([(date, hour) for hour in os.listdir(os.path.join(sample_data_path, date))])\n","        self.column_map = {\n","            'bid': 0,\n","            'buyout': 1,\n","            'quantity': 2,\n","            'item_id': 3,\n","            'time_left': 4,\n","            'hours_since_first_appearance': 5,\n","            'historical_price': 6\n","        }\n","        print(f\"Dataset size: {len(self)}\")\n","    def __len__(self):\n","        return len(self.sample_hours)\n","    def __getitem__(self, idx):\n","        date, hour = self.sample_hours[idx]\n","        file_path = os.path.join(self.sample_data_path, date, hour)\n","        data = torch.load(file_path)\n","        X = []\n","        y = []\n","        for item_id, item_data in data.items():\n","            item_X = item_data[:, :-1]\n","            item_y = item_data[:, -1]\n","            datetime_str = f\"{date} 00:00:00\"\n","            if (item_id, datetime_str) in self.weekly_historical_prices.index:\n","                historical_price = self.weekly_historical_prices.loc[item_id, datetime_str]['price']\n","            else:\n","                historical_price = item_X[:, self.column_map['buyout']].median()\n","            item_X = torch.cat([item_X, torch.ones(item_X.shape[0], 1) * historical_price], dim=1)\n","            item_X[:, self.column_map['bid']] = item_X[:, self.column_map['bid']] * 10000\n","            item_X[:, self.column_map['buyout']] = item_X[:, self.column_map['buyout']] * 10000\n","            item_X[:, self.column_map['item_id']] = torch.tensor([self.item_to_index.get(int(item), 1) for item in item_X[:, self.column_map['item_id']]], dtype=torch.long)\n","            item_X[:, self.column_map['time_left']] = item_X[:, self.column_map['time_left']] / 48.0\n","            item_X[:, self.column_map['hours_since_first_appearance']] = item_X[:, self.column_map['hours_since_first_appearance']] / 48.0\n","            item_X[:, self.column_map['bid']] = item_X[:, self.column_map['bid']] / 1000\n","            item_X[:, self.column_map['buyout']] = item_X[:, self.column_map['buyout']] / 1000\n","            item_X[:, self.column_map['historical_price']] = item_X[:, self.column_map['historical_price']] / 1000\n","            item_X[:, self.column_map['quantity']] = item_X[:, self.column_map['quantity']] / 200.0\n","            X.append(item_X)\n","            y.append(item_y)\n","        return X, y"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def collate_auctions(batch):\n","    all_X = []\n","    all_y = []\n","    for X, y in batch:\n","        all_X.extend(X)\n","        all_y.extend(y)\n","    lengths = [x.size(0) for x in all_X]\n","    max_length = max(lengths)\n","    padded_X = [F.pad(x, (0, 0, 0, max_length - x.size(0))) for x in all_X]\n","    padded_y = [F.pad(y, (0, max_length - y.size(0))) for y in all_y]\n","    X = torch.stack(padded_X)\n","    y = torch.stack(padded_y)\n","    return X, y"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset size: 48\n"]}],"source":["\n","dataset = AuctionDataset('sample', item_to_index, weekly_historical_prices)\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=False, collate_fn=collate_auctions)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["An error occurred while loading the model: Error(s) in loading state_dict for AuctionPredictor:\n","\tsize mismatch for encoder.embedding.weight: copying a param with shape torch.Size([10398, 64]) from checkpoint, the shape in current model is torch.Size([5571, 64]).\n","\tsize mismatch for encoder.rnn.weight_ih_l0: copying a param with shape torch.Size([512, 70]) from checkpoint, the shape in current model is torch.Size([512, 71]).\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_51919/2150072882.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(model_path, map_location=device)\n"]}],"source":["\n","embedding_size = 64\n","encoder_hidden_size = 128\n","decoder_hidden_size = 128\n","model = AuctionPredictor(input_size=7,\n","                         encoder_hidden_size=encoder_hidden_size,\n","                         decoder_hidden_size=decoder_hidden_size,\n","                         item_index=3,\n","                         embedding_size=embedding_size,\n","                         dropout_p=0.1,\n","                         bidirectional=False).to(device)\n","model_path = 'models/rnn_model.pt'\n","if not os.path.exists(model_path):\n","    model_path = '../eval/models/rnn_model.pt'\n","\n","try:\n","    checkpoint = torch.load(model_path, map_location=device)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    model.eval()\n","    print('Pre-trained RNN model loaded successfully.')\n","except FileNotFoundError:\n","    print(f'Error: The model file {model_path} was not found.')\n","except Exception as e:\n","    print(f'An error occurred while loading the model: {str(e)}')"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/2 [00:00<?, ?it/s]/tmp/ipykernel_51919/3233434816.py:25: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  data = torch.load(file_path)\n","  0%|          | 0/2 [00:00<?, ?it/s]\n"]},{"ename":"UnpicklingError","evalue":"invalid load key, '{'.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mae, predictions[mask], actual_values[mask]\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Evaluate the RNN model and calculate MAE\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m rnn_mae, rnn_predictions, actual_values \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_rnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRNN Model MAE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrnn_mae\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n","Cell \u001b[0;32mIn[9], line 10\u001b[0m, in \u001b[0;36mevaluate_rnn\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m      7\u001b[0m actual_values \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader):\n\u001b[1;32m     11\u001b[0m         X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m         y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","Cell \u001b[0;32mIn[5], line 25\u001b[0m, in \u001b[0;36mAuctionDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     23\u001b[0m date, hour \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_hours[idx]\n\u001b[1;32m     24\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_data_path, date, hour)\n\u001b[0;32m---> 25\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m X \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     27\u001b[0m y \u001b[38;5;241m=\u001b[39m []\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:1114\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1113\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_legacy_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:1338\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreadinto\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m<\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m   1333\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1334\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load does not work with file-like objects that do not implement readinto on Python 3.8.0 and 3.8.1. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1335\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReceived object of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(f)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. Please update to Python 3.8.2 or newer to restore this \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1336\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctionality.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1338\u001b[0m magic_number \u001b[38;5;241m=\u001b[39m \u001b[43mpickle_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic_number \u001b[38;5;241m!=\u001b[39m MAGIC_NUMBER:\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid magic number; corrupt file?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, '{'."]}],"source":["from sklearn.metrics import mean_absolute_error\n","from tqdm import tqdm\n","\n","def evaluate_rnn(model, dataloader):\n","    model.eval()\n","    predictions = []\n","    actual_values = []\n","\n","    with torch.no_grad():\n","        for X, y in tqdm(dataloader):\n","            X = X.to(device)\n","            y = y.to(device)\n","            output = model(X)\n","            predictions.extend(output.squeeze().cpu().numpy().flatten())\n","            actual_values.extend(y.cpu().numpy().flatten())\n","\n","    predictions = np.array(predictions)\n","    actual_values = np.array(actual_values)\n","    mask = actual_values != 0\n","    mae = mean_absolute_error(actual_values[mask], predictions[mask])\n","    return mae, predictions[mask], actual_values[mask]\n","\n","rnn_mae, rnn_predictions, actual_values = evaluate_rnn(model, dataloader)\n","print(f'RNN Model MAE: {rnn_mae}')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
