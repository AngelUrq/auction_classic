{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from auction_predictor import AuctionPredictor\n",
    "from auction_dataset import AuctionDataset\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.width = None\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items shape: (10396, 13)\n",
      "Number of unique items: 10396\n",
      "Historical prices loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "items = pd.read_csv('../data/items.csv')\n",
    "print(\"Items shape:\", items.shape)\n",
    "n_items = len(items)\n",
    "item_to_index = {item_id: i + 2 for i, item_id in enumerate(items['item_id'])}\n",
    "item_to_index[0] = 0 \n",
    "item_to_index[1] = 1  \n",
    "print(f\"Number of unique items: {n_items}\")\n",
    "historical_prices_path = '../data/historical_prices.csv'\n",
    "if not os.path.exists(historical_prices_path):\n",
    "    historical_prices_path = 'historical_prices.csv'\n",
    "\n",
    "try:\n",
    "    weekly_historical_prices = pd.read_csv(historical_prices_path)\n",
    "    weekly_historical_prices['datetime'] = weekly_historical_prices['datetime'].astype(str)\n",
    "    weekly_historical_prices.set_index(['item_id', 'datetime'], inplace=True)\n",
    "    print('Historical prices loaded successfully.')\n",
    "except FileNotFoundError:\n",
    "    print(f'Error: The historical prices file {historical_prices_path} was not found.')\n",
    "    weekly_historical_prices = pd.DataFrame(columns=['item_id', 'datetime', 'price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 30030.82it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 51834.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading file sample/26-08-2024/20240826T22.json: Expecting value: line 1 column 1 (char 0)\n",
      "Processed 354499 auctions.\n",
      "Example of processed auction: [2.384481e+06 2.509979e+06 1.000000e+00 5.274800e+04 5.000000e-01\n",
      " 1.000000e+00 2.509979e+06]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "time_left_mapping = {\n",
    "    'VERY_LONG': 48,\n",
    "    'LONG': 12,\n",
    "    'MEDIUM': 2,\n",
    "    'SHORT': 0.5\n",
    "}\n",
    "\n",
    "def process_auction_data(auctions):\n",
    "    processed_data = []\n",
    "    \n",
    "    for auction in auctions:\n",
    "        if not isinstance(auction, dict) or 'item' not in auction or 'id' not in auction['item']:\n",
    "            print(f\"Unexpected structure in auction: {auction}\")\n",
    "            continue\n",
    "\n",
    "        item_id = auction['item']['id']\n",
    "        time_left_numeric = time_left_mapping.get(auction['time_left'], 0)\n",
    "        \n",
    "        processed_auction = [\n",
    "            auction['bid'], \n",
    "            auction['buyout'], \n",
    "            auction['quantity'], \n",
    "            item_id,  \n",
    "            time_left_numeric, \n",
    "            auction['quantity'],  \n",
    "            auction['buyout']  \n",
    "        ]\n",
    "        processed_data.append(processed_auction)\n",
    "    return np.array(processed_data)\n",
    "\n",
    "def load_auctions_from_sample(data_dir='sample/'):\n",
    "    file_info = {}\n",
    "\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        for filename in tqdm(files):\n",
    "            filepath = os.path.join(root, filename)\n",
    "            date = datetime.strptime(filename.split('.')[0], '%Y%m%dT%H')\n",
    "            file_info[filepath] = date\n",
    "\n",
    "    file_info = {k: v for k, v in sorted(file_info.items(), key=lambda item: item[1])}\n",
    "    \n",
    "    all_auctions = []\n",
    "    \n",
    "    for filepath in list(file_info.keys()):\n",
    "        with open(filepath, 'r') as f:\n",
    "            try:\n",
    "                json_data = json.load(f)\n",
    "                \n",
    "                if 'auctions' not in json_data:\n",
    "                    print(f\"File {filepath} does not contain 'auctions' key, skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                auction_data = json_data['auctions']\n",
    "                \n",
    "                if not auction_data:\n",
    "                    print(f\"File {filepath} is empty, skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                all_auctions.extend(auction_data)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error loading file {filepath}: {e}\")\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error loading file {filepath}: {e}\")\n",
    "                continue\n",
    "\n",
    "    return all_auctions\n",
    "\n",
    "data_dir = 'sample/'\n",
    "auction_data = load_auctions_from_sample(data_dir)\n",
    "data = process_auction_data(auction_data)\n",
    "\n",
    "print(f\"Processed {len(data)} auctions.\")\n",
    "print(f\"Example of processed auction: {data[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique items: 10396\n"
     ]
    }
   ],
   "source": [
    "file_path = '../data/items.csv'\n",
    "\n",
    "try:\n",
    "    items = pd.read_csv(file_path)\n",
    "    n_items = len(items)\n",
    "    \n",
    "    item_to_index = {item_id: i + 2 for i, item_id in enumerate(items['item_id'])}\n",
    "    item_to_index[0] = 0\n",
    "    item_to_index[1] = 1\n",
    "    \n",
    "    print(f\"Number of unique items: {n_items}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File 'items.csv' not found at the specified path: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model parameters: 509249\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 64\n",
    "encoder_hidden_size = 128\n",
    "decoder_hidden_size = 128\n",
    "epochs = 10\n",
    "n_items = 3\n",
    "\n",
    "model = AuctionPredictor(\n",
    "    n_items=n_items,             \n",
    "    input_size=6,                   \n",
    "    encoder_hidden_size=encoder_hidden_size,\n",
    "    decoder_hidden_size=decoder_hidden_size,\n",
    "    item_index=3,                   \n",
    "    embedding_size=embedding_size,\n",
    "    dropout_p=0.1,\n",
    "    bidirectional=False\n",
    ").to(device)\n",
    "\n",
    "print(f'Number of model parameters: {sum(p.numel() for p in model.parameters())}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'models/rnn_model.pt'\n",
    "if not os.path.exists(model_path):\n",
    "    model_path = '../eval/models/rnn_model.pt'  \n",
    "try:\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()  \n",
    "    print('Pre-trained RNN model loaded successfully.')\n",
    "except FileNotFoundError:\n",
    "    print(f'Error: The model file {model_path} was not found.')\n",
    "except Exception as e:\n",
    "    print(f'An error occurred while loading the model: {str(e)}')\n",
    "\n",
    "def evaluate_rnn(model, data):\n",
    "    predictions = []\n",
    "    actual_values = []\n",
    "\n",
    "    for X, y in data:\n",
    "        prediction = model.predict(X)  \n",
    "        predictions.append(prediction)\n",
    "        actual_values.append(y)\n",
    "    predictions = np.array(predictions)\n",
    "    actual_values = np.array(actual_values)\n",
    "\n",
    "    mae = mean_absolute_error(actual_values, predictions)\n",
    "    return mae\n",
    "rnn_mae = evaluate_rnn(model, data)\n",
    "print(f'RNN Model MAE: {rnn_mae}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
