{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQLite Database Initialization\n",
    "This section initializes the SQLite database by creating necessary tables such as Items, Auctions, and ActionEvents. It ensures the existence of the required tables and sets up the database schema.\n",
    "\n",
    "File and Configuration Setup\n",
    "Additionally, it creates other essential files and configurations needed for subsequent operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm auction.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "\n",
    "db_path = 'auction.db'\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS Items (\n",
    "        item_id INT PRIMARY KEY,\n",
    "        item_name TEXT,\n",
    "        quality TEXT,\n",
    "        item_level INT,\n",
    "        required_level INT,\n",
    "        item_class TEXT,\n",
    "        item_subclass TEXT,\n",
    "        purchase_price_gold INT,\n",
    "        purchase_price_silver INT,\n",
    "        sell_price_gold INT,\n",
    "        sell_price_silver INT,\n",
    "        max_count INT,\n",
    "        is_stackable INT\n",
    "    )\n",
    "''')\n",
    "\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS Auctions (\n",
    "        auction_id INT PRIMARY KEY,\n",
    "        bid INT,\n",
    "        buyout INT,\n",
    "        quantity INT,\n",
    "        time_left TEXT,\n",
    "        item_id INT\n",
    "    )\n",
    "''')\n",
    "\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS ActionEvents (\n",
    "        auction_id INT,\n",
    "        record DATETIME,\n",
    "        PRIMARY KEY (auction_id, record),\n",
    "        FOREIGN KEY (auction_id) REFERENCES Auctions(auction_id)\n",
    "    )\n",
    "''')\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "file_info = {}\n",
    "data_dir = 'sample/'\n",
    "\n",
    "for root, dirs, files in os.walk(data_dir):\n",
    "    for filename in tqdm(files):\n",
    "        filepath = os.path.join(root, filename)\n",
    "        date = datetime.strptime(filename.split('.')[0], '%Y%m%dT%H')\n",
    "\n",
    "        file_info[filepath] = date\n",
    "\n",
    "file_info = {k: v for k, v in sorted(file_info.items(), key=lambda item: item[1])}\n",
    "filenames = list(file_info.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MySQL Items Data Retrieval\n",
    "In this part, the script retrieves data from a MySQL database. It reads the MySQL database configuration from a JSON file, establishes a connection, and fetches data from the Items table. The retrieved data is then loaded into a Pandas DataFrame.\n",
    "\n",
    "SQLite Database Update\n",
    "After retrieving the data, the script connects to the SQLite database, deletes all existing records from the Items table, and appends the newly fetched data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import sqlite3\n",
    "\n",
    "db_path = 'auction.db'\n",
    "data_dir = 'sample/'\n",
    "db = sqlite3.connect(db_path)\n",
    "cursor = db.cursor()\n",
    "\n",
    "for i, filepath in tqdm(enumerate(filenames)):\n",
    "    try:\n",
    "        data = json.load(open(filepath, \"r\"))\n",
    "    except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "        print(f\"Error reading file {filepath}: {e}\")\n",
    "        continue\n",
    "\n",
    "    auction_record = datetime.strptime(filename[:-5], \"%Y%m%dT%H\")\n",
    "\n",
    "    if i == 0:\n",
    "        auction_ids = []\n",
    "        auctions_data = []\n",
    "\n",
    "        for auction in data[\"auctions\"]:\n",
    "            if auction[\"id\"] not in auction_ids:\n",
    "                auctions_data.append((auction[\"id\"], auction[\"bid\"], auction[\"buyout\"], auction[\"quantity\"], auction[\"time_left\"], auction[\"item\"][\"id\"]))\n",
    "                auction_ids.append(auction[\"id\"])\n",
    "\n",
    "        try:\n",
    "            cursor.executemany(\"\"\"\n",
    "                INSERT INTO Auctions (auction_id, bid, buyout, quantity, time_left, item_id)\n",
    "                VALUES (?, ?, ?, ?, ?, ?)\n",
    "            \"\"\", auctions_data)\n",
    "            db.commit()\n",
    "        except sqlite3.Error as err:\n",
    "            db.rollback()\n",
    "            print(f\"Error inserting auction data for file {filepath} in Auctions: {err}\")\n",
    "\n",
    "    action_events_data = []\n",
    "    for auction in data[\"auctions\"]:\n",
    "        action_events_data.append((auction[\"id\"], auction_record.strftime('%Y-%m-%d %H:%M:%S')))\n",
    "            \n",
    "    try:\n",
    "        cursor.executemany(\"\"\"\n",
    "            INSERT OR REPLACE INTO ActionEvents (auction_id, record)\n",
    "            VALUES (?, ?)\n",
    "        \"\"\", action_events_data)\n",
    "        db.commit()\n",
    "    except sqlite3.Error as err:\n",
    "        db.rollback()\n",
    "        print(f\"Error inserting auction events for file {filepath} in ActionEvents: {err}\")\n",
    "\n",
    "cursor.close()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auction Data and Items Storage\n",
    "This section processes JSON files containing auction data. It iterates through the files, extracts relevant information, and inserts it into the Auctions and ActionEvents tables of the SQLite database.\n",
    "\n",
    "Data Import from Pandas DataFrame\n",
    "Moreover, it initializes a connection to the SQLite database and imports data from a Pandas DataFrame into the Items table. This DataFrame is generated from MySQL database retrieval, ensuring the SQLite Items table is up-to-date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import json\n",
    "import sqlite3\n",
    "\n",
    "with open('../data/config.json') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "db_path = 'auction.db'\n",
    "query = \"SELECT * FROM Items\"\n",
    "\n",
    "def import_items():\n",
    "    try:\n",
    "        mysql_db = mysql.connector.connect(**config['database'])\n",
    "    except mysql.connector.Error as err:\n",
    "        print(err)\n",
    "        return\n",
    "\n",
    "    cursor = mysql_db.cursor()\n",
    "\n",
    "    items = cursor.execute(query)\n",
    "    items = cursor.fetchall()\n",
    "\n",
    "    mysql_db.close()\n",
    "    cursor.close()\n",
    "\n",
    "    try:\n",
    "        db = sqlite3.connect(db_path)\n",
    "        print(\"Connected to SQLite\")\n",
    "    except sqlite3.Error as err:\n",
    "        return\n",
    "\n",
    "    cursor = db.cursor()\n",
    "    cursor.executemany(\"\"\"\n",
    "        INSERT OR REPLACE INTO Items (item_id, item_name, quality, item_level, required_level, item_class, item_subclass, purchase_price_gold, purchase_price_silver, sell_price_gold, sell_price_silver, max_count, is_stackable)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    \"\"\", items)\n",
    "\n",
    "    db.commit()\n",
    "\n",
    "    cursor.close()\n",
    "    db.close()\n",
    "\n",
    "    print(\"Inserted items into SQLite: \" + str(len(items)))\n",
    "\n",
    "import_items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is responsible for connecting to an SQLite database, executing a SQL query involving multiple tables, and retrieving the results. These results are stored in the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT\n",
    "        a.auction_id,\n",
    "        a.bid / 10000 AS bid_in_gold,\n",
    "        a.buyout / 10000 AS buyout_in_gold,\n",
    "        (a.buyout / 10000) / a.quantity AS unit_price,\n",
    "        a.quantity,\n",
    "        a.time_left,\n",
    "        a.item_id,\n",
    "        i.item_name,\n",
    "        i.quality,\n",
    "        i.item_class,\n",
    "        i.item_subclass,\n",
    "        i.is_stackable,\n",
    "        i.purchase_price_gold,\n",
    "        i.required_level,\n",
    "        i.item_level,\n",
    "        i.sell_price_gold,\n",
    "        MIN(ae.record) AS first_appearance_timestamp,\n",
    "        strftime('%Y', MIN(ae.record)) AS first_appearance_year,\n",
    "        strftime('%m', MIN(ae.record)) AS first_appearance_month,\n",
    "        strftime('%d', MIN(ae.record)) AS first_appearance_day,\n",
    "        strftime('%H', MIN(ae.record)) AS first_appearance_hour,\n",
    "        COUNT(*) AS hours_on_sale\n",
    "    FROM Auctions a\n",
    "    JOIN ActionEvents ae ON a.auction_id = ae.auction_id\n",
    "    JOIN Items i ON i.item_id = a.item_id\n",
    "    GROUP BY a.auction_id\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query)\n",
    "results = cursor.fetchall()\n",
    "\n",
    "conn.close()\n",
    "\n",
    "df = pd.DataFrame(results, columns=[i[0] for i in cursor.description])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "organize the results of a SQL query into a DataFrame, and then apply some form of preprocessing to that data using functions from a module called preprocess_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def map_time_left(df):\n",
    "    df['time_left'] = np.where(df['time_left'] == 'SHORT', 0.5, df['time_left'])\n",
    "    df['time_left'] = np.where(df['time_left'] == 'MEDIUM', 2, df['time_left'])\n",
    "    df['time_left'] = np.where(df['time_left'] == 'LONG', 12, df['time_left'])\n",
    "    df['time_left'] = np.where(df['time_left'] == 'VERY_LONG', 48, df['time_left'])\n",
    "\n",
    "    df['time_left'].value_counts()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def compute_median_competitor_price(df):\n",
    "    df['median_buyout_price'] = df.groupby(by=['item_id', 'first_appearance_year', 'first_appearance_month', 'first_appearance_day'])['buyout_in_gold'].transform('median')\n",
    "    df['median_bid_price'] = df.groupby(by=['item_id', 'first_appearance_year', 'first_appearance_month', 'first_appearance_day'])['bid_in_gold'].transform('median')\n",
    "    df['median_unit_price'] = df.groupby(by=['item_id', 'first_appearance_year', 'first_appearance_month', 'first_appearance_day'])['unit_price'].transform('median')\n",
    "\n",
    "    df['rank_buyout_price'] = df.groupby(by=['item_id', 'first_appearance_year', 'first_appearance_month', 'first_appearance_day'])['buyout_in_gold'].rank(ascending=True)\n",
    "    df['rank_bid_price'] = df.groupby(by=['item_id', 'first_appearance_year', 'first_appearance_month', 'first_appearance_day'])['bid_in_gold'].rank(ascending=True)\n",
    "    df['rank_unit_price'] = df.groupby(by=['item_id', 'first_appearance_year', 'first_appearance_month', 'first_appearance_day'])['unit_price'].rank(ascending=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def compute_avg_competitor_price(df):\n",
    "    avg_competitor_price = df.groupby(by=['item_id', 'first_appearance_year', 'first_appearance_month', 'first_appearance_day'])['unit_price'].mean().reset_index(name='avg_competitor_price')\n",
    "    std_competitor_price = df.groupby(by=['item_id', 'first_appearance_year', 'first_appearance_month', 'first_appearance_day'])['unit_price'].std().reset_index(name='std_competitor_price')\n",
    "\n",
    "    df_merged = pd.merge(df, avg_competitor_price, on=['item_id', 'first_appearance_year', 'first_appearance_month', 'first_appearance_day'], how='left')\n",
    "    df_merged['avg_competitor_price'] = df_merged['avg_competitor_price'].fillna(0)\n",
    "\n",
    "    df_merged = pd.merge(df_merged, std_competitor_price, on=['item_id', 'first_appearance_year', 'first_appearance_month', 'first_appearance_day'], how='left')\n",
    "    df_merged['std_competitor_price'] = df_merged['std_competitor_price'].fillna(0)\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "\n",
    "def compute_competitor_count(df):\n",
    "    competitor_count = df.groupby(by=['item_id', 'first_appearance_year', 'first_appearance_month', 'first_appearance_day'])['unit_price'].count().reset_index(name='competitor_count')\n",
    "\n",
    "    df_merged = pd.merge(df, competitor_count, on=['item_id', 'first_appearance_year', 'first_appearance_month', 'first_appearance_day'], how='left')\n",
    "    df_merged['competitor_count'] = df_merged['competitor_count'].fillna(0)\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "\n",
    "def compute_minimum_competitor_price(df):\n",
    "    minimum_competitor_price = df.groupby(by=['item_id', 'first_appearance_year', 'first_appearance_month', 'first_appearance_day'])['unit_price'].quantile(0.15).reset_index(name='lowest_competitor_price')\n",
    "\n",
    "    df_merged = pd.merge(df, minimum_competitor_price, on=['item_id', 'first_appearance_year', 'first_appearance_month', 'first_appearance_day'], how='left')\n",
    "    df_merged['lowest_competitor_price'] = df_merged['lowest_competitor_price'].fillna(0)\n",
    "    \n",
    "    return df_merged\n",
    "\n",
    "\n",
    "def compute_top_competitor_price(df):\n",
    "    top_competitor_price = df.groupby(by=['item_id', 'first_appearance_year', 'first_appearance_month', 'first_appearance_day'])['unit_price'].quantile(0.80).reset_index(name='top_competitor_price')\n",
    "\n",
    "    df_merged = pd.merge(df, top_competitor_price, on=['item_id', 'first_appearance_year', 'first_appearance_month', 'first_appearance_day'], how='left')\n",
    "    df_merged['top_competitor_price'] = df_merged['top_competitor_price'].fillna(0)\n",
    "    \n",
    "    return df_merged\n",
    "\n",
    "\n",
    "def compute_relative_differences(df):\n",
    "    df['relative_price_difference'] = (df['unit_price'] - df['median_unit_price']) / (df['median_unit_price'] + 1e-6)\n",
    "    df['relative_price_difference'] = df['relative_price_difference'].fillna(0)\n",
    "\n",
    "    df['relative_avg_price_difference'] = (df['unit_price'] - df['avg_competitor_price']) / (df['std_competitor_price'] + 1e-6)\n",
    "    df['relative_avg_price_difference'] = df['relative_avg_price_difference'].fillna(0)\n",
    "\n",
    "    df['relative_buyout_difference'] = (df['buyout_in_gold'] - df['median_buyout_price']) / (df['median_buyout_price'] + 1e-6)\n",
    "    df['relative_buyout_difference'] = df['relative_buyout_difference'].fillna(0)\n",
    "\n",
    "    df['relative_bid_difference'] = (df['bid_in_gold'] - df['median_bid_price']) / (df['median_bid_price'] + 1e-6)\n",
    "    df['relative_bid_difference'] = df['relative_bid_difference'].fillna(0)\n",
    "\n",
    "    df['relative_price_to_lowest_competitor'] = (df['unit_price'] - df['lowest_competitor_price']) / (df['lowest_competitor_price'] + 1e-6)\n",
    "    df['relative_price_to_lowest_competitor'] = df['relative_price_to_lowest_competitor'].fillna(0)\n",
    "\n",
    "    df['relative_price_to_top_competitor'] = (df['unit_price'] - df['top_competitor_price']) / (df['top_competitor_price'] + 1e-6)\n",
    "    df['relative_price_to_top_competitor'] = df['relative_price_to_top_competitor'].fillna(0)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df = map_time_left(df)\n",
    "    df = compute_median_competitor_price(df)\n",
    "    df = compute_avg_competitor_price(df)\n",
    "    df = compute_competitor_count(df)\n",
    "    df = compute_minimum_competitor_price(df)\n",
    "    df = compute_top_competitor_price(df)\n",
    "    df = compute_relative_differences(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = preprocess_data(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [\n",
    "    'quantity',\n",
    "    'unit_price',\n",
    "    'bid_in_gold',\n",
    "    'buyout_in_gold',\n",
    "    'time_left',\n",
    "    'median_buyout_price',\n",
    "    'median_bid_price',\n",
    "    'median_unit_price',\n",
    "    'lowest_competitor_price',\n",
    "    'avg_competitor_price',\n",
    "    'std_competitor_price',\n",
    "    'top_competitor_price',\n",
    "    'competitor_count',\n",
    "    'rank_buyout_price',\n",
    "    'rank_bid_price',\n",
    "    'rank_unit_price',\n",
    "    'relative_price_difference',\n",
    "    'relative_avg_price_difference',\n",
    "    'relative_buyout_difference',\n",
    "    'relative_bid_difference',\n",
    "    'relative_price_to_lowest_competitor',\n",
    "    'relative_price_to_top_competitor',\n",
    "    'purchase_price_gold',\n",
    "    'sell_price_gold',\n",
    "    'required_level',\n",
    "    'item_level'\n",
    "]\n",
    "\n",
    "categorical_columns_ordinal = [\n",
    "    'item_id',\n",
    "    'quality',\n",
    "    'item_class',\n",
    "    'item_subclass'\n",
    "]\n",
    "categorical_columns_onehot = [\n",
    "  'is_stackable'\n",
    "]\n",
    "\n",
    "X = df[numerical_columns + categorical_columns_ordinal + categorical_columns_onehot]\n",
    "y = df['hours_on_sale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "num_transformer = StandardScaler()\n",
    "ordinal_transformer = OrdinalEncoder()\n",
    "onehot_transformer = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "column_transformer = make_column_transformer(\n",
    "    #(num_transformer, numerical_columns),\n",
    "    (ordinal_transformer, categorical_columns_ordinal),\n",
    "    (onehot_transformer, categorical_columns_onehot),\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "X = column_transformer.fit_transform(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loads a trained model from a file, makes predictions on a data set, calculates the RMSE and displays the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "pd.options.display.float_format = '{:.0f}'.format\n",
    "\n",
    "with open('models/linear_model.pkl', 'rb') as model_file:\n",
    "    model = pickle.load(model_file)\n",
    "\n",
    "predictions = model.predict(X)\n",
    "df['prediction'] = predictions\n",
    "df[['item_name', 'item_class', 'unit_price', 'buyout_in_gold', 'hours_on_sale', 'prediction']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = mean_squared_error(y, predictions, squared=False)\n",
    "\n",
    "print(\"RMSE:\", rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
