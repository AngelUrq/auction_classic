{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQLite Database Initialization\n",
    "This section initializes the SQLite database by creating necessary tables such as Items, Auctions, and ActionEvents. It ensures the existence of the required tables and sets up the database schema.\n",
    "\n",
    "File and Configuration Setup\n",
    "Additionally, it creates other essential files and configurations needed for subsequent operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import sqlite3\n",
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "wd = Path(os.path.dirname(os.path.abspath(\"__file__\"))).parent.resolve()\n",
    "sys.path.append(str(wd))\n",
    "\n",
    "from data.transformers import add_features, transform_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = 'auction.db'\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS Items (\n",
    "        item_id INT PRIMARY KEY,\n",
    "        item_name TEXT,\n",
    "        quality TEXT,\n",
    "        item_level INT,\n",
    "        required_level INT,\n",
    "        item_class TEXT,\n",
    "        item_subclass TEXT,\n",
    "        purchase_price_gold INT,\n",
    "        purchase_price_silver INT,\n",
    "        sell_price_gold INT,\n",
    "        sell_price_silver INT,\n",
    "        max_count INT,\n",
    "        is_stackable INT\n",
    "    )\n",
    "''')\n",
    "\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS Auctions (\n",
    "        auction_id INT PRIMARY KEY,\n",
    "        bid INT,\n",
    "        buyout INT,\n",
    "        quantity INT,\n",
    "        time_left TEXT,\n",
    "        item_id INT\n",
    "    )\n",
    "''')\n",
    "\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS ActionEvents (\n",
    "        auction_id INT,\n",
    "        record DATETIME,\n",
    "        PRIMARY KEY (auction_id, record),\n",
    "        FOREIGN KEY (auction_id) REFERENCES Auctions(auction_id)\n",
    "    )\n",
    "''')\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_info = {}\n",
    "data_dir = 'sample/'\n",
    "\n",
    "for root, dirs, files in os.walk(data_dir):\n",
    "    for filename in tqdm(files):\n",
    "        filepath = os.path.join(root, filename)\n",
    "        date = datetime.strptime(filename.split('.')[0], '%Y%m%dT%H')\n",
    "\n",
    "        file_info[filepath] = date\n",
    "\n",
    "file_info = {k: v for k, v in sorted(file_info.items(), key=lambda item: item[1])}\n",
    "filenames = list(file_info.keys())\n",
    "\n",
    "filenames[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MySQL Items Data Retrieval\n",
    "In this part, the script retrieves data from a MySQL database. It reads the MySQL database configuration from a JSON file, establishes a connection, and fetches data from the Items table. The retrieved data is then loaded into a Pandas DataFrame.\n",
    "\n",
    "SQLite Database Update\n",
    "After retrieving the data, the script connects to the SQLite database, deletes all existing records from the Items table, and appends the newly fetched data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = 'auction.db'\n",
    "data_dir = 'sample/'\n",
    "db = sqlite3.connect(db_path)\n",
    "cursor = db.cursor()\n",
    "auction_ids = {}\n",
    "\n",
    "for i, filepath in tqdm(enumerate(filenames)):\n",
    "    print(f\"Processing file {filepath} ({i+1}/{len(filenames)})\")\n",
    "    \n",
    "    try:\n",
    "        data = json.load(open(filepath, \"r\"))\n",
    "    except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "        print(f\"Error reading file {filepath}: {e}\")\n",
    "        continue\n",
    "\n",
    "    filename = filepath.split('/')[-1]\n",
    "    auction_record = datetime.strptime(filename[:-5], \"%Y%m%dT%H\")\n",
    "\n",
    "    if i == 0:\n",
    "        auctions_data = []\n",
    "\n",
    "        for auction in data[\"auctions\"]:\n",
    "            if auction[\"id\"] not in auction_ids:\n",
    "                auctions_data.append((auction[\"id\"], auction[\"bid\"], auction[\"buyout\"], auction[\"quantity\"], auction[\"time_left\"], auction[\"item\"][\"id\"]))\n",
    "                auction_ids.update({auction[\"id\"]: 1})\n",
    "\n",
    "        try:\n",
    "            cursor.executemany(\"\"\"\n",
    "                INSERT INTO Auctions (auction_id, bid, buyout, quantity, time_left, item_id)\n",
    "                VALUES (?, ?, ?, ?, ?, ?)\n",
    "            \"\"\", auctions_data)\n",
    "        except sqlite3.Error as err:\n",
    "            db.rollback()\n",
    "            print(f\"Error inserting auction data for file {filepath} in Auctions: {err}\")\n",
    "\n",
    "    action_events_data = []\n",
    "    for auction in data[\"auctions\"]:\n",
    "        if auction[\"id\"] in auction_ids:\n",
    "            action_events_data.append((auction[\"id\"], auction_record.strftime('%Y-%m-%d %H:%M:%S')))\n",
    "            \n",
    "    try:\n",
    "        cursor.executemany(\"\"\"\n",
    "            INSERT OR REPLACE INTO ActionEvents (auction_id, record)\n",
    "            VALUES (?, ?)\n",
    "        \"\"\", action_events_data)\n",
    "    except sqlite3.Error as err:\n",
    "        db.rollback()\n",
    "        print(f\"Error inserting auction events for file {filepath} in ActionEvents: {err}\")\n",
    "\n",
    "db.commit()\n",
    "cursor.close()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auction Data and Items Storage\n",
    "This section processes JSON files containing auction data. It iterates through the files, extracts relevant information, and inserts it into the Auctions and ActionEvents tables of the SQLite database.\n",
    "\n",
    "Data Import from Pandas DataFrame\n",
    "Moreover, it initializes a connection to the SQLite database and imports data from a Pandas DataFrame into the Items table. This DataFrame is generated from MySQL database retrieval, ensuring the SQLite Items table is up-to-date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df = pd.read_csv('items.csv')\n",
    "items = [tuple(x) for x in items_df.values]\n",
    "\n",
    "try:\n",
    "    db = sqlite3.connect(db_path)\n",
    "    print(\"Connected to SQLite\")\n",
    "except sqlite3.Error as err:\n",
    "    print(f\"Error connecting to SQLite: {err}\")\n",
    "\n",
    "cursor = db.cursor()\n",
    "\n",
    "cursor.execute('''\n",
    "    DROP TABLE IF EXISTS Items\n",
    "''')\n",
    "\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS Items (\n",
    "        item_id INT PRIMARY KEY,\n",
    "        item_name TEXT,\n",
    "        quality TEXT,\n",
    "        item_level INT,\n",
    "        required_level INT,\n",
    "        item_class TEXT,\n",
    "        item_subclass TEXT,\n",
    "        purchase_price_gold INT,\n",
    "        purchase_price_silver INT,\n",
    "        sell_price_gold INT,\n",
    "        sell_price_silver INT,\n",
    "        max_count INT,\n",
    "        is_stackable INT\n",
    "    )\n",
    "''')\n",
    "\n",
    "try:\n",
    "    print(items[0])\n",
    "    cursor.executemany(\"\"\"\n",
    "        INSERT OR REPLACE INTO Items (item_id, item_name, quality, item_level, required_level, item_class, item_subclass, purchase_price_gold, purchase_price_silver, sell_price_gold, sell_price_silver, max_count, is_stackable)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    \"\"\", items)\n",
    "    db.commit()\n",
    "    print(\"Inserted items into SQLite: \" + str(len(items)))\n",
    "except sqlite3.Error as err:\n",
    "    print(f\"Error executing SQL query: {err}\")\n",
    "\n",
    "finally:\n",
    "    cursor.close()\n",
    "    db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read auction.db\n",
    "It is responsible for connecting to an SQLite database, executing a SQL query involving multiple tables, and retrieving the results. These results are stored in the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = 'auction.db'\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT\n",
    "        a.auction_id,\n",
    "        a.bid / 10000.0 AS bid_in_gold,\n",
    "        a.buyout / 10000.0 AS buyout_in_gold,\n",
    "        (a.buyout / 10000.0) / a.quantity AS unit_price,\n",
    "        a.quantity,\n",
    "        a.time_left,\n",
    "        a.item_id,\n",
    "        i.item_name,\n",
    "        i.quality,\n",
    "        i.item_class,\n",
    "        i.item_subclass,\n",
    "        i.is_stackable,\n",
    "        i.purchase_price_gold,\n",
    "        i.required_level,\n",
    "        i.item_level,\n",
    "        i.sell_price_gold,\n",
    "        MIN(ae.record) AS first_appearance_timestamp,\n",
    "        strftime('%Y', MIN(ae.record)) AS first_appearance_year,\n",
    "        strftime('%m', MIN(ae.record)) AS first_appearance_month,\n",
    "        strftime('%d', MIN(ae.record)) AS first_appearance_day,\n",
    "        strftime('%H', MIN(ae.record)) AS first_appearance_hour,\n",
    "        COUNT(*) AS hours_on_sale\n",
    "    FROM Auctions a\n",
    "    JOIN ActionEvents ae ON a.auction_id = ae.auction_id\n",
    "    JOIN Items i ON i.item_id = a.item_id\n",
    "    WHERE A.time_left <> 'SHORT'\n",
    "    GROUP BY a.auction_id\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query)\n",
    "results = cursor.fetchall()\n",
    "\n",
    "conn.close()\n",
    "\n",
    "df = pd.DataFrame(results, columns=[i[0] for i in cursor.description])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time_left'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataframe shape before duplicates {df.shape}')\n",
    "\n",
    "df = df.drop_duplicates(subset=['bid_in_gold', 'buyout_in_gold', 'quantity', 'time_left', 'first_appearance_timestamp', 'item_id'])\n",
    "df = df[(df['time_left'] != 2)]\n",
    "\n",
    "print(f'Dataframe shape after duplicates {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = transform_data(df)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loads a trained model from a file, makes predictions on a data set, calculates the RMSE and displays the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.0f}'.format\n",
    "\n",
    "with open('models/forest_model.pkl', 'rb') as model_file:\n",
    "    model = pickle.load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X)\n",
    "df['prediction'] = predictions\n",
    "df[['item_name', 'item_class', 'unit_price', 'bid_in_gold', 'buyout_in_gold', 'time_left', 'hours_on_sale', 'prediction']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mae = mean_absolute_error(y, predictions)\n",
    "\n",
    "print(\"MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['item_name', 'item_class', 'unit_price', 'bid_in_gold', 'buyout_in_gold', 'item_id', 'quantity', 'first_appearance_timestamp', 'median_buyout_price',\n",
    "       'median_bid_price', 'median_unit_price', 'rank_buyout_price',\n",
    "       'rank_bid_price', 'rank_unit_price', 'avg_competitor_price',\n",
    "       'std_competitor_price', 'competitor_count', 'lowest_competitor_price',\n",
    "       'top_competitor_price', 'relative_price_difference',\n",
    "       'relative_avg_price_difference', 'relative_buyout_difference',\n",
    "       'relative_bid_difference', 'relative_price_to_lowest_competitor',\n",
    "       'relative_price_to_top_competitor', 'time_left', 'hours_on_sale', 'prediction']].to_excel('MAE_6_45.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_excel('MAE_5_54.xlsx')\n",
    "df_test = pd.read_excel('MAE_6_45.xlsx')\n",
    "\n",
    "df_val['error'] = np.abs(df_val['hours_on_sale'] - df_val['prediction'])\n",
    "df_test['error'] = np.abs(df_test['hours_on_sale'] - df_test['prediction'])\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_val[['bid_in_gold', 'buyout_in_gold',\n",
    "       'unit_price', 'quantity', 'time_left', 'item_id',\n",
    "       'median_buyout_price', 'median_bid_price', 'median_unit_price',\n",
    "       'rank_buyout_price', 'rank_bid_price', 'rank_unit_price',\n",
    "       'avg_competitor_price', 'std_competitor_price', 'competitor_count',\n",
    "       'lowest_competitor_price', 'top_competitor_price',\n",
    "       'relative_price_difference', 'relative_avg_price_difference',\n",
    "       'relative_buyout_difference', 'relative_bid_difference',\n",
    "       'relative_price_to_lowest_competitor',\n",
    "       'relative_price_to_top_competitor','hours_on_sale', 'prediction', 'error']].corr()\n",
    "\n",
    "corr_matrix = corr_matrix[['prediction', 'hours_on_sale', 'error']]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation with Prediction and Hours on Sale - MAE 5.54')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_test[['bid_in_gold', 'buyout_in_gold',\n",
    "       'unit_price', 'quantity', 'time_left', 'item_id',\n",
    "       'median_buyout_price', 'median_bid_price', 'median_unit_price',\n",
    "       'rank_buyout_price', 'rank_bid_price', 'rank_unit_price',\n",
    "       'avg_competitor_price', 'std_competitor_price', 'competitor_count',\n",
    "       'lowest_competitor_price', 'top_competitor_price',\n",
    "       'relative_price_difference', 'relative_avg_price_difference',\n",
    "       'relative_buyout_difference', 'relative_bid_difference',\n",
    "       'relative_price_to_lowest_competitor',\n",
    "       'relative_price_to_top_competitor','hours_on_sale', 'prediction', 'error']].corr()\n",
    "\n",
    "corr_matrix = corr_matrix[['prediction', 'hours_on_sale', 'error']]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation with Prediction and Hours on Sale - MAE 6.45')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_errors_val = df_val.groupby('time_left')['error'].mean().reset_index()\n",
    "mean_errors_test = df_test.groupby('time_left')['error'].mean().reset_index()\n",
    "\n",
    "print(mean_errors_val)\n",
    "print(mean_errors_test)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Create a bar plot with the validation and test bars side by side\n",
    "bar_width = 0.35\n",
    "x = np.arange(len(mean_errors_val))\n",
    "ax.bar(x - bar_width/2, mean_errors_val['error'], bar_width, label='Validation (5.54 MAE)')\n",
    "ax.bar(x + bar_width/2, mean_errors_test['error'], bar_width, label='Test (6.45 MAE)')\n",
    "\n",
    "# Set the x-axis tick labels\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(mean_errors_val['time_left'])\n",
    "\n",
    "plt.xlabel('Time Left')\n",
    "plt.ylabel('Mean Error')\n",
    "plt.title('Mean Error by Time Left (Validation vs Test)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
