{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "wd = Path(os.path.dirname(os.path.abspath(\"__file__\"))).parent.resolve()\n",
    "sys.path.append(str(wd))\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "from src.models.auction_transformer import AuctionTransformer\n",
    "from src.models.inference import predict_dataframe\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.width = None\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_time = datetime.strptime(\"2025-04-12 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "mappings_dir = '../generated/mappings'\n",
    "\n",
    "with open(os.path.join(mappings_dir, 'item_to_idx.json'), 'r') as f:\n",
    "        item_to_idx = json.load(f)\n",
    "\n",
    "with open(os.path.join(mappings_dir, 'context_to_idx.json'), 'r') as f:\n",
    "    context_to_idx = json.load(f)\n",
    "    \n",
    "with open(os.path.join(mappings_dir, 'bonus_to_idx.json'), 'r') as f:\n",
    "    bonus_to_idx = json.load(f)\n",
    "\n",
    "with open(os.path.join(mappings_dir, 'modtype_to_idx.json'), 'r') as f:\n",
    "    modtype_to_idx = json.load(f)\n",
    "\n",
    "feature_stats = torch.load('../generated/feature_stats.pt')\n",
    "\n",
    "time_left_mapping = {\n",
    "    'VERY_LONG': 48,\n",
    "    'LONG': 12,\n",
    "    'MEDIUM': 2,\n",
    "    'SHORT': 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.utils import load_auctions_from_sample\n",
    "\n",
    "data_dir = '../data/sample/'\n",
    "\n",
    "df_auctions = load_auctions_from_sample(data_dir, prediction_time, time_left_mapping, item_to_idx, context_to_idx, bonus_to_idx, modtype_to_idx)\n",
    "\n",
    "print(\"Auctions shape:\", df_auctions.shape)\n",
    "df_auctions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auctions[['current_hours', 'hours_on_sale']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AuctionTransformer.load_from_checkpoint(\n",
    "    '../models/auction_transformer_40M_39GB/last.ckpt',\n",
    "    map_location=device\n",
    ")\n",
    "\n",
    "print(f'Number of model parameters: {sum(p.numel() for p in model.parameters())}')\n",
    "model.eval()\n",
    "print('Pre-trained Transformer model loaded successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.inference import predict_dataframe\n",
    "\n",
    "model = model.to('cuda')\n",
    "df_auctions = predict_dataframe(model, df_auctions, prediction_time, feature_stats)\n",
    "\n",
    "print(\"Mean hours on sale:\", df_auctions['hours_on_sale'].mean())\n",
    "print(\"Mean prediction:\", df_auctions['prediction'].mean())\n",
    "print(\"Mean sale probability:\", df_auctions['sale_probability'].mean())\n",
    "\n",
    "mae = mean_absolute_error(df_auctions['hours_on_sale'], df_auctions['prediction'])\n",
    "print(f\"Mean absolute error: {mae}\")\n",
    "\n",
    "df_auctions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auctions_filtered = df_auctions[df_auctions['current_hours'] <= 0]\n",
    "df_auctions_filtered = df_auctions_filtered[df_auctions_filtered['time_left'] > 12.0]\n",
    "#df_auctions_filtered = df_auctions_filtered[df_auctions_filtered['prediction'] <= 8.0]\n",
    "len(df_auctions_filtered)\n",
    "\n",
    "mae = mean_absolute_error(df_auctions_filtered['hours_on_sale'], df_auctions_filtered['prediction'])\n",
    "print(f\"Mean absolute error: {mae}\") # 5.43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auctions_filtered[['item_index', 'buyout','quantity', 'time_left', 'current_hours', 'hours_on_sale', 'prediction', 'sale_probability']].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "df_auctions_filtered['sold_gt'] = df_auctions_filtered['hours_on_sale'] <= 8.0\n",
    "df_auctions_filtered['sold_pred'] = df_auctions_filtered['sale_probability'] >= 0.75\n",
    "\n",
    "accuracy = accuracy_score(df_auctions_filtered['sold_gt'], df_auctions_filtered['sold_pred'])\n",
    "precision = precision_score(df_auctions_filtered['sold_gt'], df_auctions_filtered['sold_pred'])\n",
    "recall = recall_score(df_auctions_filtered['sold_gt'], df_auctions_filtered['sold_pred'])\n",
    "f1 = f1_score(df_auctions_filtered['sold_gt'], df_auctions_filtered['sold_pred'])\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'item_index',\n",
    "    'bid',\n",
    "    'buyout',\n",
    "    'quantity',\n",
    "    'time_left',\n",
    "    'first_appearance',\n",
    "    'last_appearance',\n",
    "    'current_hours',\n",
    "    'hours_on_sale',\n",
    "    'prediction',\n",
    "    'sale_probability'\n",
    "]\n",
    "\n",
    "df_error = df_auctions_filtered[columns].copy()\n",
    "df_error['error'] = np.abs(df_error['hours_on_sale'] - df_error['prediction'])\n",
    "\n",
    "df_error.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error['time_left'].hist(bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df_error[['hours_on_sale', 'prediction']])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bins for hours_on_sale\n",
    "bins = [(0,12), (12,24), (24,48)]\n",
    "\n",
    "# Calculate mean error for each bin\n",
    "for start, end in bins:\n",
    "    mask = (df_error['hours_on_sale'] >= start) & (df_error['hours_on_sale'] <= end)\n",
    "    mean_error = df_error[mask]['error'].mean()\n",
    "    print(f\"Mean error for hours {start}-{end}: {mean_error:.2f}\")\n",
    "\n",
    "# Create boxplot showing error distribution in each bin\n",
    "error_by_bin = []\n",
    "labels = []\n",
    "for start, end in bins:\n",
    "    mask = (df_error['hours_on_sale'] >= start) & (df_error['hours_on_sale'] <= end)\n",
    "    error_by_bin.append(df_error[mask]['error'])\n",
    "    labels.append(f\"{start}-{end}h\")\n",
    "\n",
    "plt.boxplot(error_by_bin, labels=labels)\n",
    "plt.title(\"Error Distribution by Hours on Sale\")\n",
    "plt.ylabel(\"Absolute Error\")\n",
    "plt.xlabel(\"Hours on Sale Range\") \n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of hours on sale and prediction\n",
    "plt.hist(df_error['hours_on_sale'], bins=100, alpha=0.5, label='Hours on sale')\n",
    "plt.hist(df_error['prediction'], bins=100, alpha=0.5, label='Prediction')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_error['current_hours'], bins=15)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in evaluating the model when the items are recently published, because this will be the main use case for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (df_error['current_hours'] <= 12) & (df_error['time_left'] == 48.0)\n",
    "query_df = df_error[query]\n",
    "print(f\"Mean sale probability: {query_df['sale_probability'].mean()}\")\n",
    "print(f\"Mean error: {query_df['error'].mean()}\")\n",
    "print(f\"Mean hours on sale: {query_df['hours_on_sale'].mean()}\")\n",
    "query_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df['hours_on_sale'].hist(bins=10)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_error[['bid', 'buyout', 'time_left', 'current_hours', 'sale_probability',\n",
    "                        'hours_on_sale', 'prediction', 'error']].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "sns.heatmap(corr_matrix, \n",
    "            annot=True, \n",
    "            cmap='coolwarm',\n",
    "            vmin=-1, vmax=1, \n",
    "            center=0,\n",
    "            fmt='.2f',\n",
    "            square=True) \n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "repo_root = Path.cwd().parent.resolve()\n",
    "sys.path.append(str(repo_root))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.data.auction_dataset import AuctionDataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pd.read_csv('../generated/auction_indices.csv')\n",
    "pairs = pairs[pairs['g_hours_on_sale_max'] < 50]\n",
    "pairs = pairs[pairs['g_current_hours_max'] < 50]\n",
    "\n",
    "train_pairs, val_pairs = train_test_split(pairs, test_size=0.05, random_state=42, shuffle=False)\n",
    "\n",
    "print(f\"Before filtering: {len(train_pairs)}\")\n",
    "\n",
    "train_pairs = train_pairs[train_pairs['g_hours_on_sale_len'] <= 64]\n",
    "val_pairs = val_pairs[val_pairs['g_hours_on_sale_len'] <= 64]\n",
    "\n",
    "print(f\"After filtering: {len(train_pairs)}\\n\")\n",
    "\n",
    "train_pairs = train_pairs[:int(len(train_pairs)*0.85)]\n",
    "\n",
    "print(f\"Train pairs: {len(train_pairs)}\")\n",
    "print(f\"Val pairs: {len(val_pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pairs = val_pairs[val_pairs['record'] == '2025-04-01 00:00:00']\n",
    "val_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "mappings_dir = '../generated/mappings'\n",
    "\n",
    "with open(os.path.join(mappings_dir, 'item_to_idx.json'), 'r') as f:\n",
    "    item_to_idx = json.load(f)\n",
    "\n",
    "with open(os.path.join(mappings_dir, 'context_to_idx.json'), 'r') as f:\n",
    "    context_to_idx = json.load(f)\n",
    "    \n",
    "with open(os.path.join(mappings_dir, 'bonus_to_idx.json'), 'r') as f:\n",
    "    bonus_to_idx = json.load(f)\n",
    "\n",
    "with open(os.path.join(mappings_dir, 'modtype_to_idx.json'), 'r') as f:\n",
    "    modtype_to_idx = json.load(f)\n",
    "\n",
    "feature_stats = torch.load('../generated/feature_stats.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pairs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.auction_transformer import AuctionTransformer\n",
    "\n",
    "model = AuctionTransformer.load_from_checkpoint(\n",
    "    '../models/auction_transformer_40M_39GB/last.ckpt',\n",
    "    map_location=device\n",
    ")\n",
    "\n",
    "print(f'Number of model parameters: {sum(p.numel() for p in model.parameters())}')\n",
    "model.eval()\n",
    "print('Pre-trained Transformer model loaded successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.auction_dataset import AuctionDataset\n",
    "from src.data.utils import collate_auctions\n",
    "\n",
    "batch_size = 1024\n",
    "\n",
    "val_dataset = AuctionDataset(val_pairs, feature_stats=feature_stats, path='../generated/sequences.h5')\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_auctions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "validate_and_noise.py\n",
    "─────────────────────\n",
    "Assumes you already have:\n",
    "\n",
    "* model            – your trained AuctionTransformer (on `device`)\n",
    "* val_dataloader   – torch DataLoader created from AuctionDataset\n",
    "* feature_stats    – dict with 'means' and 'stds'  (torch tensors 1-D)\n",
    "\"\"\"\n",
    "\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "# 1. Helper: build a hashable signature of everything the network\n",
    "#    can ACTUALLY distinguish once log1p+norm have been undone.\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "def auction_signature(item_idx,\n",
    "                      quantity,\n",
    "                      buyout_gold,\n",
    "                      context,\n",
    "                      time_left,\n",
    "                      current_hours,\n",
    "                      bonus_lists,\n",
    "                      modifier_types,\n",
    "                      age_bucket=1.0):    # 1-hour buckets\n",
    "    price_sig = round(float(buyout_gold), 2)          # 0.01 g precision\n",
    "    age_sig   = int(current_hours // age_bucket)\n",
    "\n",
    "    return (\n",
    "        int(item_idx),\n",
    "        int(quantity),\n",
    "        price_sig,\n",
    "        int(context),\n",
    "        int(time_left),\n",
    "        age_sig,\n",
    "        tuple(sorted(bonus_lists)),\n",
    "        tuple(sorted(modifier_types)),\n",
    "    )\n",
    "\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "# 2. Validation + noise-floor loop\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "def evaluate_with_noise(model, val_loader, feature_stats, device=\"cuda\"):\n",
    "    means = feature_stats[\"means\"].cpu().numpy()\n",
    "    stds  = feature_stats[\"stds\"].cpu().numpy()\n",
    "\n",
    "    total_mse   = 0.0\n",
    "    total_mae   = 0.0\n",
    "    total_items = 0\n",
    "\n",
    "    targets_by_sig = defaultdict(list)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Validating\"):\n",
    "            (auctions, item_index, contexts, bonus_lists,\n",
    "             modifier_types, modifier_values, current_hours,\n",
    "             time_left, buyout_ranking), y = batch\n",
    "\n",
    "            # move to device ----------------------------------------------------\n",
    "            auctions          = auctions.to(device)\n",
    "            item_index        = item_index.to(device)\n",
    "            contexts          = contexts.to(device)\n",
    "            bonus_lists       = bonus_lists.to(device)\n",
    "            modifier_types    = modifier_types.to(device)\n",
    "            modifier_values   = modifier_values.to(device)\n",
    "            current_hours     = current_hours.to(device)\n",
    "            time_left         = time_left.to(device)\n",
    "            buyout_ranking    = buyout_ranking.to(device)\n",
    "            y                 = y.to(device)\n",
    "\n",
    "            # forward -----------------------------------------------------------\n",
    "            y_hat = model((auctions, item_index, contexts, bonus_lists,\n",
    "                           modifier_types, modifier_values, buyout_ranking))\n",
    "\n",
    "            # mask: real items, full 48 h left, listed ≤12 h ago -----------------\n",
    "            mask  = (item_index != 0).float().unsqueeze(-1)\n",
    "            #mask *= (time_left == 48.0).float().unsqueeze(-1)\n",
    "            mask *= (current_hours <= 12.0).float().unsqueeze(-1)\n",
    "\n",
    "            # losses ------------------------------------------------------------\n",
    "            mse = torch.nn.functional.mse_loss(y_hat * mask,\n",
    "                                               y.unsqueeze(2) * mask,\n",
    "                                               reduction='sum')\n",
    "            mae = torch.nn.functional.l1_loss(y_hat * mask * 48.0,\n",
    "                                              y.unsqueeze(2) * mask * 48.0,\n",
    "                                              reduction='sum')\n",
    "\n",
    "            total_mse   += mse.item()\n",
    "            total_mae   += mae.item()\n",
    "            total_items += mask.sum().item()\n",
    "\n",
    "            # ----- collect targets for irreducible-noise estimate --------------\n",
    "            # work on CPU / numpy\n",
    "            y_cpu            = (y * 48.0).cpu().numpy()\n",
    "            mask_cpu         = mask.squeeze(-1).cpu().numpy()\n",
    "            item_idx_cpu     = item_index.cpu().numpy()\n",
    "            auctions_cpu     = auctions.cpu().numpy()        # z-scores\n",
    "            contexts_cpu     = contexts.cpu().numpy()\n",
    "            time_left_cpu    = time_left.cpu().numpy()\n",
    "            current_hours_cpu= current_hours.cpu().numpy()\n",
    "            bonus_lists_cpu  = bonus_lists.cpu().numpy()\n",
    "            modifier_types_cpu = modifier_types.cpu().numpy()\n",
    "\n",
    "            B, S, _ = auctions_cpu.shape\n",
    "            for b in range(B):\n",
    "                for s in range(S):\n",
    "                    if not mask_cpu[b, s]:\n",
    "                        continue\n",
    "\n",
    "                    # -------- undo standardisation + log1p for price ------------\n",
    "                    buyout_norm = auctions_cpu[b, s, 1]\n",
    "                    log_buyout  = buyout_norm * stds[1] + means[1]\n",
    "                    buyout_gold = np.expm1(log_buyout)\n",
    "\n",
    "                    # quantity column is already linear but was standardised\n",
    "                    qty_norm   = auctions_cpu[b, s, 2]\n",
    "                    quantity   = int(round(qty_norm * stds[2] + means[2]))\n",
    "\n",
    "                    sig = auction_signature(\n",
    "                        item_idx_cpu[b, s],\n",
    "                        quantity,\n",
    "                        buyout_gold,\n",
    "                        contexts_cpu[b, s],\n",
    "                        time_left_cpu[b, s],\n",
    "                        current_hours_cpu[b, s],\n",
    "                        bonus_lists_cpu[b, s][bonus_lists_cpu[b, s] != 0],\n",
    "                        modifier_types_cpu[b, s][modifier_types_cpu[b, s] != 0],\n",
    "                    )\n",
    "\n",
    "                    targets_by_sig[sig].append(float(y_cpu[b, s]))\n",
    "\n",
    "    # ── aggregate --------------------------------------------------------------\n",
    "    avg_mse = total_mse / total_items\n",
    "    avg_mae = total_mae / total_items\n",
    "\n",
    "    noise_sum   = 0.0\n",
    "    noise_count = 0\n",
    "    for t_list in targets_by_sig.values():\n",
    "        if len(t_list) < 2:\n",
    "            continue\n",
    "        for a, b in itertools.combinations(t_list, 2):\n",
    "            noise_sum   += abs(a - b)\n",
    "            noise_count += 1\n",
    "\n",
    "    irreducible_mae = noise_sum / noise_count if noise_count else 0.0\n",
    "\n",
    "    print(f\"Validation MSE          : {avg_mse:.4f}\")\n",
    "    print(f\"Validation MAE          : {avg_mae:.4f} hours\")\n",
    "    print(f\"Bayesian lower-bound MAE: {irreducible_mae:.4f} hours\")\n",
    "\n",
    "    return avg_mse, avg_mae, irreducible_mae\n",
    "\n",
    "evaluate_with_noise(model, val_dataloader, feature_stats, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.inference import predict_dataframe\n",
    "\n",
    "predict_dataframe(model, df_auctions[df_auctions['item_index'] == 13815], prediction_time, feature_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
