{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "wd = Path(os.path.dirname(os.path.abspath(\"__file__\"))).parent.resolve()\n",
    "sys.path.append(str(wd))\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "from src.models.auction_transformer import AuctionTransformer\n",
    "from src.models.inference import predict_dataframe\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.width = None\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_time = datetime.strptime(\"2025-12-25 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "max_hours_back = 72\n",
    "max_sequence_length = 4096\n",
    "\n",
    "mappings_dir = '../generated/mappings'\n",
    "\n",
    "with open(os.path.join(mappings_dir, 'item_to_idx.json'), 'r') as f:\n",
    "        item_to_idx = json.load(f)\n",
    "\n",
    "with open(os.path.join(mappings_dir, 'context_to_idx.json'), 'r') as f:\n",
    "    context_to_idx = json.load(f)\n",
    "    \n",
    "with open(os.path.join(mappings_dir, 'bonus_to_idx.json'), 'r') as f:\n",
    "    bonus_to_idx = json.load(f)\n",
    "\n",
    "with open(os.path.join(mappings_dir, 'modtype_to_idx.json'), 'r') as f:\n",
    "    modtype_to_idx = json.load(f)\n",
    "\n",
    "feature_stats = torch.load('../generated/feature_stats.pt')\n",
    "\n",
    "time_left_mapping = {\n",
    "    'VERY_LONG': 48,\n",
    "    'LONG': 12,\n",
    "    'MEDIUM': 2,\n",
    "    'SHORT': 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pass 1/2: appearances: 100%|██████████| 225/225 [01:15<00:00,  2.97it/s]\n",
      "Pass 2/2: rows: 100%|██████████| 225/225 [03:37<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built dataframe with 17265784 rows from 225 snapshots [2025-12-20 00:00, 2025-12-30 00:00], include_targets=True\n",
      "Skipped 1596685 items because they were not in the dictionary.\n",
      "Auctions shape: (17265784, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_index</th>\n",
       "      <th>bid</th>\n",
       "      <th>buyout</th>\n",
       "      <th>quantity</th>\n",
       "      <th>time_left</th>\n",
       "      <th>context</th>\n",
       "      <th>bonus_lists</th>\n",
       "      <th>modifier_types</th>\n",
       "      <th>modifier_values</th>\n",
       "      <th>snapshot_time</th>\n",
       "      <th>time_offset</th>\n",
       "      <th>hour_of_week</th>\n",
       "      <th>current_hours</th>\n",
       "      <th>hours_on_sale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7760875</th>\n",
       "      <td>463319546</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>445698.03</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>49</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-12-25</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7760876</th>\n",
       "      <td>463319578</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>445698.03</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>49</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-12-25</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7760877</th>\n",
       "      <td>461933379</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1500.00</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-12-25</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>20.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7760878</th>\n",
       "      <td>464326727</td>\n",
       "      <td>3</td>\n",
       "      <td>14478.27</td>\n",
       "      <td>15240.28</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-12-25</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7760879</th>\n",
       "      <td>464326746</td>\n",
       "      <td>3</td>\n",
       "      <td>14478.27</td>\n",
       "      <td>15240.28</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-12-25</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  item_index       bid     buyout  quantity  time_left  \\\n",
       "7760875  463319546           2      0.00  445698.03         1       48.0   \n",
       "7760876  463319578           2      0.00  445698.03         1       48.0   \n",
       "7760877  461933379           3      0.00    1500.00         1       48.0   \n",
       "7760878  464326727           3  14478.27   15240.28         1       48.0   \n",
       "7760879  464326746           3  14478.27   15240.28         1       48.0   \n",
       "\n",
       "         context bonus_lists modifier_types modifier_values snapshot_time  \\\n",
       "7760875       49          []             []              []    2025-12-25   \n",
       "7760876       49          []             []              []    2025-12-25   \n",
       "7760877        0          []             []              []    2025-12-25   \n",
       "7760878        0          []             []              []    2025-12-25   \n",
       "7760879        0          []             []              []    2025-12-25   \n",
       "\n",
       "         time_offset  hour_of_week  current_hours  hours_on_sale  \n",
       "7760875            0            72            7.0           16.0  \n",
       "7760876            0            72            7.0           16.0  \n",
       "7760877            0            72           20.0           27.0  \n",
       "7760878            0            72            0.0           23.0  \n",
       "7760879            0            72            0.0           23.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data.utils import load_auctions_from_sample\n",
    "\n",
    "data_dir = '../data/tww/auctions/'\n",
    "\n",
    "df_auctions = load_auctions_from_sample(data_dir, prediction_time, time_left_mapping, item_to_idx, context_to_idx, bonus_to_idx, modtype_to_idx, max_hours_back=max_hours_back)\n",
    "\n",
    "print(\"Auctions shape:\", df_auctions.shape)\n",
    "df_auctions[df_auctions['snapshot_time'] == prediction_time].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model parameters: 4203908\n",
      "Pre-trained Transformer model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "model = AuctionTransformer.load_from_checkpoint(\n",
    "    '../models/transformer-4.2M-quantile-historical_72-lr1e-04-bs64/last-v3.ckpt',\n",
    "    map_location=device\n",
    ")\n",
    "\n",
    "print(f'Number of model parameters: {sum(p.numel() for p in model.parameters())}')\n",
    "model.eval()\n",
    "print('Pre-trained Transformer model loaded successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with nan prediction_q50: 0\n",
      "Mean hours on sale: 18.949494200361922\n",
      "Mean prediction: 19.11852606128927\n",
      "Mean absolute error: 3.0375485775312234\n"
     ]
    }
   ],
   "source": [
    "from src.models.inference import predict_dataframe\n",
    "\n",
    "model = model.to('cuda')\n",
    "df_auctions = predict_dataframe(model, df_auctions, prediction_time, feature_stats, max_hours_back=max_hours_back, max_sequence_length=max_sequence_length)\n",
    "\n",
    "df_predictions = df_auctions[df_auctions['time_offset'] == 0]\n",
    "print(f\"Number of rows with nan prediction_q50: {df_predictions['prediction_q50'].isna().sum()}\")\n",
    "df_predictions = df_predictions[df_predictions['prediction_q50'].notna()]\n",
    "\n",
    "print(\"Mean hours on sale:\", df_predictions['hours_on_sale'].mean())\n",
    "print(\"Mean prediction:\", df_predictions['prediction_q50'].mean())\n",
    "\n",
    "mae = mean_absolute_error(df_predictions['hours_on_sale'], df_predictions['prediction_q50'])\n",
    "print(f\"Mean absolute error: {mae}\") # 3.14 -> 24 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 3.217777777777778 for 18 auctions\n"
     ]
    }
   ],
   "source": [
    "df_auctions_filtered = df_predictions[df_predictions['current_hours'] == 0]\n",
    "df_auctions_filtered = df_auctions_filtered[df_auctions_filtered['time_left'] == 48.0]\n",
    "df_auctions_filtered = df_auctions_filtered[df_auctions_filtered['is_short_duration'] >= 0.65]\n",
    "\n",
    "df_auctions_filtered['prediction_interval'] = df_auctions_filtered['prediction_q90'] - df_auctions_filtered['prediction_q10']\n",
    "\n",
    "mae = mean_absolute_error(df_auctions_filtered['hours_on_sale'], df_auctions_filtered['prediction_q50'])\n",
    "print(f\"Mean absolute error: {mae} for {len(df_auctions_filtered)} auctions\") # 6.54 -> 24 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Classification Metrics (threshold: 8 hours):\n",
      "Accuracy:  1.0000\n",
      "Precision: 1.0000\n",
      "Recall:    1.0000\n",
      "F1 Score:  1.0000\n",
      "\n",
      "Total samples: 18\n",
      "Positive class (< 8h): 18 (100.0%)\n",
      "Negative class (>= 8h): 0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "y_true = (df_auctions_filtered['hours_on_sale'] <= 8.0).astype(int)\n",
    "y_pred = (df_auctions_filtered['is_short_duration'] >= 0.6).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Binary Classification Metrics (threshold: 8 hours):\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"\\nTotal samples: {len(df_auctions_filtered)}\")\n",
    "print(f\"Positive class (< 8h): {y_true.sum()} ({y_true.mean()*100:.1f}%)\")\n",
    "print(f\"Negative class (>= 8h): {(~y_true.astype(bool)).sum()} ({(1-y_true.mean())*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_index</th>\n",
       "      <th>buyout</th>\n",
       "      <th>quantity</th>\n",
       "      <th>time_left</th>\n",
       "      <th>current_hours</th>\n",
       "      <th>hours_on_sale</th>\n",
       "      <th>prediction_q10</th>\n",
       "      <th>prediction_q50</th>\n",
       "      <th>prediction_q90</th>\n",
       "      <th>is_short_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7821304</th>\n",
       "      <td>16932</td>\n",
       "      <td>298.35</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>2.40</td>\n",
       "      <td>16.45</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7769230</th>\n",
       "      <td>2262</td>\n",
       "      <td>5233.01</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>3.16</td>\n",
       "      <td>19.56</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7823070</th>\n",
       "      <td>17036</td>\n",
       "      <td>155.61</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>2.15</td>\n",
       "      <td>16.15</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7819197</th>\n",
       "      <td>16243</td>\n",
       "      <td>11268.38</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>3.21</td>\n",
       "      <td>15.69</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7820823</th>\n",
       "      <td>16873</td>\n",
       "      <td>250.44</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3.48</td>\n",
       "      <td>17.50</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7819189</th>\n",
       "      <td>16242</td>\n",
       "      <td>3358.51</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>3.05</td>\n",
       "      <td>15.83</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7821020</th>\n",
       "      <td>16891</td>\n",
       "      <td>798.01</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>3.98</td>\n",
       "      <td>17.12</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7823105</th>\n",
       "      <td>17039</td>\n",
       "      <td>157.25</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>2.54</td>\n",
       "      <td>16.36</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7820799</th>\n",
       "      <td>16872</td>\n",
       "      <td>250.63</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>2.21</td>\n",
       "      <td>15.89</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7821224</th>\n",
       "      <td>16909</td>\n",
       "      <td>799.52</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>4.16</td>\n",
       "      <td>17.20</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_index    buyout  quantity  time_left  current_hours  \\\n",
       "7821304       16932    298.35         1       48.0            0.0   \n",
       "7769230        2262   5233.01         1       48.0            0.0   \n",
       "7823070       17036    155.61         1       48.0            0.0   \n",
       "7819197       16243  11268.38         1       48.0            0.0   \n",
       "7820823       16873    250.44         1       48.0            0.0   \n",
       "7819189       16242   3358.51         1       48.0            0.0   \n",
       "7821020       16891    798.01         1       48.0            0.0   \n",
       "7823105       17039    157.25         1       48.0            0.0   \n",
       "7820799       16872    250.63         1       48.0            0.0   \n",
       "7821224       16909    799.52         1       48.0            0.0   \n",
       "\n",
       "         hours_on_sale  prediction_q10  prediction_q50  prediction_q90  \\\n",
       "7821304            0.0           -0.00            2.40           16.45   \n",
       "7769230            0.0           -0.18            3.16           19.56   \n",
       "7823070            0.0           -0.21            2.15           16.15   \n",
       "7819197            0.0           -0.16            3.21           15.69   \n",
       "7820823            0.0            0.10            3.48           17.50   \n",
       "7819189            0.0           -0.20            3.05           15.83   \n",
       "7821020            8.0            0.13            3.98           17.12   \n",
       "7823105            0.0           -0.14            2.54           16.36   \n",
       "7820799            0.0           -0.02            2.21           15.89   \n",
       "7821224            0.0            0.32            4.16           17.20   \n",
       "\n",
       "         is_short_duration  \n",
       "7821304               0.78  \n",
       "7769230               0.71  \n",
       "7823070               0.80  \n",
       "7819197               0.76  \n",
       "7820823               0.71  \n",
       "7819189               0.76  \n",
       "7821020               0.67  \n",
       "7823105               0.77  \n",
       "7820799               0.80  \n",
       "7821224               0.66  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_auctions_filtered[['item_index', 'buyout','quantity', 'time_left', 'current_hours', 'hours_on_sale', 'prediction_q10', 'prediction_q50', 'prediction_q90', 'is_short_duration']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auctions_filtered['coverage'] = (df_auctions_filtered['prediction_q10'] <= df_auctions_filtered['hours_on_sale']) & (df_auctions_filtered['hours_on_sale'] <= df_auctions_filtered['prediction_q90'])\n",
    "df_auctions_filtered['coverage'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "df_auctions_filtered = df_predictions[df_predictions['current_hours'] == 0]\n",
    "df_auctions_filtered = df_auctions_filtered[df_auctions_filtered['time_left'] == 48.0]\n",
    "\n",
    "df_auctions_filtered['sold_gt'] = df_auctions_filtered['hours_on_sale'] <= 8\n",
    "\n",
    "df_auctions_filtered['sold_pred'] = (df_auctions_filtered['prediction_q50'] <= 8.0) & (df_auctions_filtered['is_short_duration'] >= 0.7)\n",
    "\n",
    "num_positive = df_auctions_filtered['sold_gt'].sum()\n",
    "num_negative = len(df_auctions_filtered) - num_positive\n",
    "\n",
    "print(f\"Total samples: {len(df_auctions_filtered)}\")\n",
    "print(f\"Positive (sold ≤ hours): {num_positive}\")\n",
    "print(f\"Negative (not sold > hours): {num_negative}\")\n",
    "print(f\"Predicted positive: {df_auctions_filtered['sold_pred'].sum()}\")\n",
    "print(f\"Predicted negative: {len(df_auctions_filtered) - df_auctions_filtered['sold_pred'].sum()}\")\n",
    "print(f\"Class balance: {num_positive / len(df_auctions_filtered):.2%} positives\")\n",
    "\n",
    "accuracy = accuracy_score(df_auctions_filtered['sold_gt'], df_auctions_filtered['sold_pred'])\n",
    "precision = precision_score(df_auctions_filtered['sold_gt'], df_auctions_filtered['sold_pred'])\n",
    "recall = recall_score(df_auctions_filtered['sold_gt'], df_auctions_filtered['sold_pred'])\n",
    "f1 = f1_score(df_auctions_filtered['sold_gt'], df_auctions_filtered['sold_pred'])\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision} (when it claims it will sell, it is right in {precision:.2%} of the cases)\")\n",
    "print(f\"Recall: {recall} (of the ones that will sell, it catches {recall:.2%} of them)\")\n",
    "print(f\"F1 score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(df_auctions_filtered['sold_gt'], df_auctions_filtered['sold_pred'])\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Not Sold\", \"Sold\"])\n",
    "disp.plot(cmap=\"Blues\", values_format='d')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'item_index',\n",
    "    'bid',\n",
    "    'buyout',\n",
    "    'quantity',\n",
    "    'time_left',\n",
    "    'current_hours',\n",
    "    'hours_on_sale',\n",
    "    'prediction_q10',\n",
    "    'prediction_q50',\n",
    "    'prediction_q90',\n",
    "    'prediction_interval',\n",
    "    'sale_probability'\n",
    "]\n",
    "\n",
    "df_error = df_auctions_filtered[columns].copy()\n",
    "df_error['error'] = np.abs(df_error['hours_on_sale'] - df_error['prediction_q50'])\n",
    "\n",
    "df_error.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error['time_left'].hist(bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df_error[['hours_on_sale', 'prediction_q10', 'prediction_q50', 'prediction_q90']])\n",
    "plt.xticks(ticks=[1,2,3,4], labels=['hours_on_sale', 'prediction_q10', 'prediction_q50', 'prediction_q90'])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bins for hours_on_sale\n",
    "bins = [(0,12), (12,24), (24,48)]\n",
    "\n",
    "# Calculate mean error for each bin\n",
    "for start, end in bins:\n",
    "    mask = (df_error['hours_on_sale'] >= start) & (df_error['hours_on_sale'] <= end)\n",
    "    mean_error = df_error[mask]['error'].mean()\n",
    "    print(f\"Mean error for hours {start}-{end}: {mean_error:.2f}\")\n",
    "\n",
    "# Create boxplot showing error distribution in each bin\n",
    "error_by_bin = []\n",
    "labels = []\n",
    "for start, end in bins:\n",
    "    mask = (df_error['hours_on_sale'] >= start) & (df_error['hours_on_sale'] <= end)\n",
    "    error_by_bin.append(df_error[mask]['error'])\n",
    "    labels.append(f\"{start}-{end}h\")\n",
    "\n",
    "plt.boxplot(error_by_bin, labels=labels)\n",
    "plt.title(\"Error Distribution by Hours on Sale\")\n",
    "plt.ylabel(\"Absolute Error\")\n",
    "plt.xlabel(\"Hours on Sale Range\") \n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of hours on sale and prediction\n",
    "plt.hist(df_error['hours_on_sale'], bins=100, alpha=0.5, label='Hours on sale')\n",
    "plt.hist(df_error['prediction_q50'], bins=100, alpha=0.5, label='Prediction')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_error['current_hours'], bins=15)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in evaluating the model when the items are recently published, because this will be the main use case for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (df_error['current_hours'] <= 12) & (df_error['time_left'] == 48.0)\n",
    "query_df = df_error[query]\n",
    "print(f\"Mean sale probability: {query_df['sale_probability'].mean()}\")\n",
    "print(f\"Mean error: {query_df['error'].mean()}\")\n",
    "print(f\"Mean hours on sale: {query_df['hours_on_sale'].mean()}\")\n",
    "query_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df['hours_on_sale'].hist(bins=10)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_error[['bid', 'buyout', 'time_left', 'current_hours', 'sale_probability',\n",
    "                        'hours_on_sale', 'prediction_q10', 'prediction_q50', 'prediction_q90', 'prediction_interval', 'error']].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "sns.heatmap(corr_matrix, \n",
    "            annot=True, \n",
    "            cmap='coolwarm',\n",
    "            vmin=-1, vmax=1, \n",
    "            center=0,\n",
    "            fmt='.2f',\n",
    "            square=True) \n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "repo_root = Path.cwd().parent.resolve()\n",
    "sys.path.append(str(repo_root))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.data.auction_dataset import AuctionDataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = [\n",
    "    (\"g_hours_on_sale_max\", \"<=\", 50),\n",
    "    (\"g_current_hours_max\", \"<=\", 50),\n",
    "    (\"g_hours_on_sale_len\", \"<=\", 64),\n",
    "    (\"record\", \">=\", \"2025-07-01\"),\n",
    "    (\"record\", \"<=\", \"2025-09-01\"),\n",
    "]\n",
    "\n",
    "pairs = pd.read_parquet(\"../generated/indices.parquet\", engine=\"pyarrow\", filters=filters)\n",
    "\n",
    "split_idx = int(len(pairs) * 0.95)\n",
    "\n",
    "train_pairs = pairs.iloc[:split_idx]\n",
    "train_pairs = train_pairs.iloc[: int(len(train_pairs) * 0.90)]\n",
    "\n",
    "print(f\"Train pairs: {len(train_pairs)}\")\n",
    "\n",
    "val_pairs = pairs.iloc[split_idx:]\n",
    "\n",
    "print(f\"Val pairs: {len(val_pairs)}\")\n",
    "\n",
    "del pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.auction_dataset import AuctionDataset\n",
    "from src.data.utils import collate_auctions\n",
    "\n",
    "batch_size = 16\n",
    "max_hours_back = 24\n",
    "\n",
    "val_dataset = AuctionDataset(val_pairs, feature_stats=feature_stats, path='../generated/sequences.h5', max_hours_back=max_hours_back)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_auctions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate_and_noise.py\n",
    "\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "# 1) Helper: build a hashable signature of everything the network can actually\n",
    "#    distinguish once log1p + norm have been undone.\n",
    "#    (Same fields as before; model now also sees hour_of_week/time_offset, but\n",
    "#     we keep the signature aligned with original invariants.)\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "def auction_signature(item_idx,\n",
    "                      quantity,\n",
    "                      buyout_gold,\n",
    "                      context,\n",
    "                      time_left,\n",
    "                      current_hours,\n",
    "                      bonus_lists,\n",
    "                      modifier_types,\n",
    "                      age_bucket=1.0):  # 1-hour buckets\n",
    "    price_sig = round(float(buyout_gold), 2)   # 0.01 g precision\n",
    "    age_sig   = int(current_hours // age_bucket)\n",
    "\n",
    "    return (\n",
    "        int(item_idx),\n",
    "        int(quantity),\n",
    "        price_sig,\n",
    "        int(context),\n",
    "        int(time_left),\n",
    "        age_sig,\n",
    "        tuple(sorted(bonus_lists)),\n",
    "        tuple(sorted(modifier_types)),\n",
    "    )\n",
    "\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "# 2) Validation + noise-floor loop (updated for new dataloader/model)\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "def evaluate_with_noise(model, val_loader, feature_stats, max_val_batches=10000, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Args\n",
    "    ----\n",
    "    model : AuctionTransformer (quantile outputs)\n",
    "    val_loader : DataLoader yielding dict-batches from AuctionDataset\n",
    "    feature_stats : {'means': tensor(5,), 'stds': tensor(5,), ...}\n",
    "    device : str\n",
    "    require_full_duration : bool\n",
    "        If True, restrict metrics/noise-floor to time_left==48.0 (like before).\n",
    "    \"\"\"\n",
    "\n",
    "    means = feature_stats[\"means\"].detach().cpu().numpy()   # first 5 auction cols\n",
    "    stds  = feature_stats[\"stds\"].detach().cpu().numpy()\n",
    "\n",
    "    total_mse   = 0.0\n",
    "    total_mae   = 0.0\n",
    "    total_items = 0.0\n",
    "\n",
    "    targets_by_sig = defaultdict(list)\n",
    "\n",
    "    # median channel = tau=0.5\n",
    "    # Try to find it; fallback to middle channel if needed.\n",
    "    if hasattr(model, \"quantiles\") and 0.5 in model.quantiles:\n",
    "        median_idx = model.quantiles.index(0.5)\n",
    "    else:\n",
    "        # Fallback: assume 3 quantiles [0.1,0.5,0.9]\n",
    "        median_idx = 1\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        i = 0\n",
    "        for batch in tqdm(val_loader, desc=\"Validating\"):\n",
    "            if i > max_val_batches:\n",
    "                break\n",
    "            i += 1\n",
    "            # ---- move to device ------------------------------------------------\n",
    "            auctions        = batch['auctions'].to(device)           # (B,S,5) z-scored; bid/buyout were log1p pre-norm\n",
    "            item_index      = batch['item_index'].to(device)         # (B,S)\n",
    "            contexts        = batch['contexts'].to(device)           # (B,S)\n",
    "            bonus_lists     = batch['bonus_lists'].to(device)        # (B,S,K)\n",
    "            modifier_types  = batch['modifier_types'].to(device)     # (B,S,M)\n",
    "            modifier_values = batch['modifier_values'].to(device)    # (B,S,M) already log1p and normed\n",
    "            hour_of_week    = batch['hour_of_week'].to(device)       # (B,S)\n",
    "            time_offset     = batch['time_offset'].to(device)        # (B,S)\n",
    "            y               = batch['target'].to(device)             # (B,S) in HOURS (0..48)\n",
    "\n",
    "            current_hours_raw = batch['current_hours_raw'].to(device)  # (B,S)\n",
    "            time_left_raw     = batch['time_left_raw'].to(device)      # (B,S)\n",
    "\n",
    "            # ---- forward -------------------------------------------------------\n",
    "            y_hat_all = model((\n",
    "                auctions, item_index, contexts, bonus_lists,\n",
    "                modifier_types, modifier_values, hour_of_week, time_offset\n",
    "            ))                                                      # (B,S,Q)\n",
    "\n",
    "            # Take median channel (hours)\n",
    "            y_hat = y_hat_all[..., median_idx]                      # (B,S)\n",
    "\n",
    "            # ---- masks ---------------------------------------------------------\n",
    "            # real items\n",
    "            mask = (item_index != 0)\n",
    "\n",
    "            # only current auctions (time_offset == 0)\n",
    "            mask = mask & (time_offset == 0)\n",
    "            mask = mask & (current_hours_raw == 0.0)\n",
    "            mask = mask & (time_left_raw == 48.0)\n",
    "\n",
    "            mask_f = mask.float()\n",
    "\n",
    "            # ---- losses/metrics (in HOURS) ------------------------------------\n",
    "            # MSE and MAE on masked entries\n",
    "            sq_err_sum = ((y_hat - y) ** 2 * mask_f).sum()\n",
    "            abs_err_sum = (torch.abs(y_hat - y) * mask_f).sum()\n",
    "            n_items = mask_f.sum().item()\n",
    "\n",
    "            total_mse   += sq_err_sum.item()\n",
    "            total_mae   += abs_err_sum.item()\n",
    "            total_items += n_items\n",
    "\n",
    "            # ---- collect targets for irreducible-noise estimate ----------------\n",
    "            # Work on CPU/numpy\n",
    "            y_cpu               = y.detach().cpu().numpy()\n",
    "            mask_cpu            = mask.detach().cpu().numpy()\n",
    "            item_idx_cpu        = item_index.detach().cpu().numpy()\n",
    "            auctions_cpu        = auctions.detach().cpu().numpy()       # z-scores\n",
    "            contexts_cpu        = contexts.detach().cpu().numpy()\n",
    "            time_left_cpu       = time_left_raw.detach().cpu().numpy()\n",
    "            current_hours_cpu   = current_hours_raw.detach().cpu().numpy()\n",
    "            bonus_lists_cpu     = bonus_lists.detach().cpu().numpy()\n",
    "            modifier_types_cpu  = modifier_types.detach().cpu().numpy()\n",
    "\n",
    "            B, S, _ = auctions_cpu.shape\n",
    "            for b in range(B):\n",
    "                for s in range(S):\n",
    "                    if not mask_cpu[b, s]:\n",
    "                        continue\n",
    "\n",
    "                    # ---- undo standardisation + log1p for BUYOUT ---------------\n",
    "                    buyout_norm = auctions_cpu[b, s, 1]\n",
    "                    log_buyout  = buyout_norm * stds[1] + means[1]\n",
    "                    buyout_gold = np.expm1(log_buyout)\n",
    "\n",
    "                    # quantity column is linear but standardised\n",
    "                    qty_norm = auctions_cpu[b, s, 2]\n",
    "                    quantity = int(round(qty_norm * stds[2] + means[2]))\n",
    "\n",
    "                    # build signature (strip zeros from K/M dims)\n",
    "                    sig = auction_signature(\n",
    "                        item_idx_cpu[b, s],\n",
    "                        quantity,\n",
    "                        buyout_gold,\n",
    "                        contexts_cpu[b, s],\n",
    "                        time_left_cpu[b, s],\n",
    "                        current_hours_cpu[b, s],\n",
    "                        bonus_lists_cpu[b, s][bonus_lists_cpu[b, s] != 0],\n",
    "                        modifier_types_cpu[b, s][modifier_types_cpu[b, s] != 0],\n",
    "                    )\n",
    "\n",
    "                    targets_by_sig[sig].append(float(y_cpu[b, s]))\n",
    "\n",
    "    # ── aggregate --------------------------------------------------------------\n",
    "    if total_items > 0:\n",
    "        avg_mse = total_mse / total_items\n",
    "        avg_mae = total_mae / total_items\n",
    "    else:\n",
    "        avg_mse = float('nan')\n",
    "        avg_mae = float('nan')\n",
    "\n",
    "    # Pairwise absolute diffs for signatures with ≥2 targets (Bayesian lower bound)\n",
    "    noise_sum   = 0.0\n",
    "    noise_count = 0\n",
    "    for t_list in targets_by_sig.values():\n",
    "        if len(t_list) < 2:\n",
    "            continue\n",
    "        for a, b in itertools.combinations(t_list, 2):\n",
    "            noise_sum   += abs(a - b)\n",
    "            noise_count += 1\n",
    "\n",
    "    irreducible_mae = noise_sum / noise_count if noise_count else 0.0\n",
    "\n",
    "    print(f\"Validation MSE          : {avg_mse:.4f} (hours^2)\")\n",
    "    print(f\"Validation MAE          : {avg_mae:.4f} hours\")\n",
    "    print(f\"Bayesian lower-bound MAE: {irreducible_mae:.4f} hours\")\n",
    "\n",
    "    return avg_mse, avg_mae, irreducible_mae\n",
    "\n",
    "\n",
    "# Example call (match your training device variable/name)\n",
    "evaluate_with_noise(model, val_dataloader, feature_stats, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.inference import predict_dataframe\n",
    "\n",
    "predict_dataframe(model, df_auctions[df_auctions['item_index'] == 13815], prediction_time, feature_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
