{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "wd = Path(os.path.dirname(os.path.abspath(\"__file__\"))).parent.resolve()\n",
    "sys.path.append(str(wd))\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "from src.models.auction_transformer import AuctionTransformer\n",
    "from src.models.inference import predict_dataframe\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.width = None\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_time = datetime.strptime(\"2025-04-12 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "mappings_dir = '../generated/mappings'\n",
    "\n",
    "with open(os.path.join(mappings_dir, 'item_to_idx.json'), 'r') as f:\n",
    "        item_to_idx = json.load(f)\n",
    "\n",
    "with open(os.path.join(mappings_dir, 'context_to_idx.json'), 'r') as f:\n",
    "    context_to_idx = json.load(f)\n",
    "    \n",
    "with open(os.path.join(mappings_dir, 'bonus_to_idx.json'), 'r') as f:\n",
    "    bonus_to_idx = json.load(f)\n",
    "\n",
    "with open(os.path.join(mappings_dir, 'modtype_to_idx.json'), 'r') as f:\n",
    "    modtype_to_idx = json.load(f)\n",
    "\n",
    "feature_stats = torch.load('../generated/feature_stats.pt')\n",
    "\n",
    "time_left_mapping = {\n",
    "    'VERY_LONG': 48,\n",
    "    'LONG': 12,\n",
    "    'MEDIUM': 2,\n",
    "    'SHORT': 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 108007.83it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 103138.62it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 122312.63it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 114781.41it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 75065.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/sample/2025/04/10/20250410T00.json\n",
      "../data/sample/2025/04/10/20250410T01.json\n",
      "../data/sample/2025/04/10/20250410T02.json\n",
      "../data/sample/2025/04/10/20250410T03.json\n",
      "../data/sample/2025/04/10/20250410T04.json\n",
      "../data/sample/2025/04/10/20250410T05.json\n",
      "../data/sample/2025/04/10/20250410T06.json\n",
      "../data/sample/2025/04/10/20250410T07.json\n",
      "../data/sample/2025/04/10/20250410T08.json\n",
      "../data/sample/2025/04/10/20250410T09.json\n",
      "../data/sample/2025/04/10/20250410T10.json\n",
      "../data/sample/2025/04/10/20250410T11.json\n",
      "../data/sample/2025/04/10/20250410T12.json\n",
      "../data/sample/2025/04/10/20250410T13.json\n",
      "../data/sample/2025/04/10/20250410T14.json\n",
      "../data/sample/2025/04/10/20250410T15.json\n",
      "../data/sample/2025/04/10/20250410T16.json\n",
      "../data/sample/2025/04/10/20250410T17.json\n",
      "../data/sample/2025/04/10/20250410T18.json\n",
      "../data/sample/2025/04/10/20250410T19.json\n",
      "../data/sample/2025/04/10/20250410T20.json\n",
      "../data/sample/2025/04/10/20250410T21.json\n",
      "../data/sample/2025/04/10/20250410T22.json\n",
      "../data/sample/2025/04/10/20250410T23.json\n",
      "../data/sample/2025/04/11/20250411T00.json\n",
      "../data/sample/2025/04/11/20250411T01.json\n",
      "../data/sample/2025/04/11/20250411T02.json\n",
      "../data/sample/2025/04/11/20250411T03.json\n",
      "../data/sample/2025/04/11/20250411T04.json\n",
      "../data/sample/2025/04/11/20250411T05.json\n",
      "../data/sample/2025/04/11/20250411T06.json\n",
      "../data/sample/2025/04/11/20250411T07.json\n",
      "../data/sample/2025/04/11/20250411T08.json\n",
      "../data/sample/2025/04/11/20250411T09.json\n",
      "../data/sample/2025/04/11/20250411T10.json\n",
      "../data/sample/2025/04/11/20250411T11.json\n",
      "../data/sample/2025/04/11/20250411T12.json\n",
      "../data/sample/2025/04/11/20250411T13.json\n",
      "../data/sample/2025/04/11/20250411T14.json\n",
      "../data/sample/2025/04/11/20250411T15.json\n",
      "../data/sample/2025/04/11/20250411T16.json\n",
      "../data/sample/2025/04/11/20250411T17.json\n",
      "../data/sample/2025/04/11/20250411T18.json\n",
      "../data/sample/2025/04/11/20250411T19.json\n",
      "../data/sample/2025/04/11/20250411T20.json\n",
      "../data/sample/2025/04/11/20250411T21.json\n",
      "../data/sample/2025/04/11/20250411T22.json\n",
      "../data/sample/2025/04/11/20250411T23.json\n",
      "../data/sample/2025/04/12/20250412T00.json\n",
      "../data/sample/2025/04/12/20250412T01.json\n",
      "../data/sample/2025/04/12/20250412T02.json\n",
      "../data/sample/2025/04/12/20250412T03.json\n",
      "../data/sample/2025/04/12/20250412T04.json\n",
      "../data/sample/2025/04/12/20250412T05.json\n",
      "../data/sample/2025/04/12/20250412T06.json\n",
      "../data/sample/2025/04/12/20250412T07.json\n",
      "../data/sample/2025/04/12/20250412T08.json\n",
      "../data/sample/2025/04/12/20250412T09.json\n",
      "../data/sample/2025/04/12/20250412T10.json\n",
      "../data/sample/2025/04/12/20250412T11.json\n",
      "../data/sample/2025/04/12/20250412T12.json\n",
      "../data/sample/2025/04/12/20250412T13.json\n",
      "../data/sample/2025/04/12/20250412T14.json\n",
      "../data/sample/2025/04/12/20250412T15.json\n",
      "../data/sample/2025/04/12/20250412T16.json\n",
      "../data/sample/2025/04/12/20250412T17.json\n",
      "../data/sample/2025/04/12/20250412T18.json\n",
      "../data/sample/2025/04/12/20250412T19.json\n",
      "../data/sample/2025/04/12/20250412T20.json\n",
      "../data/sample/2025/04/12/20250412T21.json\n",
      "../data/sample/2025/04/12/20250412T22.json\n",
      "../data/sample/2025/04/12/20250412T23.json\n",
      "../data/sample/2025/04/13/20250413T00.json\n",
      "../data/sample/2025/04/13/20250413T01.json\n",
      "../data/sample/2025/04/13/20250413T02.json\n",
      "../data/sample/2025/04/13/20250413T03.json\n",
      "../data/sample/2025/04/13/20250413T04.json\n",
      "../data/sample/2025/04/13/20250413T05.json\n",
      "../data/sample/2025/04/13/20250413T06.json\n",
      "../data/sample/2025/04/13/20250413T07.json\n",
      "../data/sample/2025/04/13/20250413T08.json\n",
      "../data/sample/2025/04/13/20250413T09.json\n",
      "../data/sample/2025/04/13/20250413T10.json\n",
      "../data/sample/2025/04/13/20250413T11.json\n",
      "../data/sample/2025/04/13/20250413T12.json\n",
      "../data/sample/2025/04/13/20250413T13.json\n",
      "../data/sample/2025/04/13/20250413T14.json\n",
      "../data/sample/2025/04/13/20250413T15.json\n",
      "../data/sample/2025/04/13/20250413T16.json\n",
      "../data/sample/2025/04/13/20250413T17.json\n",
      "../data/sample/2025/04/13/20250413T18.json\n",
      "../data/sample/2025/04/13/20250413T19.json\n",
      "../data/sample/2025/04/13/20250413T20.json\n",
      "../data/sample/2025/04/13/20250413T21.json\n",
      "../data/sample/2025/04/13/20250413T22.json\n",
      "../data/sample/2025/04/13/20250413T23.json\n",
      "../data/sample/2025/04/14/20250414T00.json\n",
      "../data/sample/2025/04/14/20250414T01.json\n",
      "../data/sample/2025/04/14/20250414T02.json\n",
      "../data/sample/2025/04/14/20250414T03.json\n",
      "../data/sample/2025/04/14/20250414T04.json\n",
      "../data/sample/2025/04/14/20250414T05.json\n",
      "../data/sample/2025/04/14/20250414T06.json\n",
      "../data/sample/2025/04/14/20250414T07.json\n",
      "../data/sample/2025/04/14/20250414T08.json\n",
      "../data/sample/2025/04/14/20250414T09.json\n",
      "../data/sample/2025/04/14/20250414T10.json\n",
      "../data/sample/2025/04/14/20250414T11.json\n",
      "../data/sample/2025/04/14/20250414T12.json\n",
      "../data/sample/2025/04/14/20250414T13.json\n",
      "../data/sample/2025/04/14/20250414T14.json\n",
      "../data/sample/2025/04/14/20250414T15.json\n",
      "../data/sample/2025/04/14/20250414T16.json\n",
      "../data/sample/2025/04/14/20250414T17.json\n",
      "../data/sample/2025/04/14/20250414T18.json\n",
      "../data/sample/2025/04/14/20250414T19.json\n",
      "../data/sample/2025/04/14/20250414T20.json\n",
      "../data/sample/2025/04/14/20250414T21.json\n",
      "../data/sample/2025/04/14/20250414T22.json\n",
      "../data/sample/2025/04/14/20250414T23.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102808/102808 [00:01<00:00, 51806.38it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 95700 auctions\n",
      "Auctions shape: (95700, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_index</th>\n",
       "      <th>bid</th>\n",
       "      <th>buyout</th>\n",
       "      <th>quantity</th>\n",
       "      <th>time_left</th>\n",
       "      <th>context</th>\n",
       "      <th>bonus_lists</th>\n",
       "      <th>modifier_types</th>\n",
       "      <th>modifier_values</th>\n",
       "      <th>first_appearance</th>\n",
       "      <th>last_appearance</th>\n",
       "      <th>current_hours</th>\n",
       "      <th>hours_on_sale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1718619984</td>\n",
       "      <td>6689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6</td>\n",
       "      <td>[791]</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>[30, 1012]</td>\n",
       "      <td>2025-04-10</td>\n",
       "      <td>2025-04-12</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1718620180</td>\n",
       "      <td>2572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102326.64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>[805]</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>[30, 204]</td>\n",
       "      <td>2025-04-10</td>\n",
       "      <td>2025-04-12</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1718620212</td>\n",
       "      <td>2154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>594.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20</td>\n",
       "      <td>[789, 397]</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>[74, 2872]</td>\n",
       "      <td>2025-04-10</td>\n",
       "      <td>2025-04-12</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1718620263</td>\n",
       "      <td>1192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.96</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>[791]</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>[30, 2884]</td>\n",
       "      <td>2025-04-10</td>\n",
       "      <td>2025-04-12</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1718620305</td>\n",
       "      <td>1170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>312.47</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>[791]</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>[30, 2884]</td>\n",
       "      <td>2025-04-10</td>\n",
       "      <td>2025-04-12</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  item_index  bid     buyout  quantity  time_left  context  \\\n",
       "0  1718619984        6689  0.0     100.50         1        0.5        6   \n",
       "1  1718620180        2572  0.0  102326.64         1        0.5        2   \n",
       "2  1718620212        2154  0.0     594.57         1        0.5       20   \n",
       "3  1718620263        1192  0.0      44.96         1        0.5        2   \n",
       "4  1718620305        1170  0.0     312.47         1        0.5        2   \n",
       "\n",
       "  bonus_lists modifier_types modifier_values first_appearance last_appearance  \\\n",
       "0       [791]         [3, 4]      [30, 1012]       2025-04-10      2025-04-12   \n",
       "1       [805]         [3, 4]       [30, 204]       2025-04-10      2025-04-12   \n",
       "2  [789, 397]         [3, 4]      [74, 2872]       2025-04-10      2025-04-12   \n",
       "3       [791]         [3, 4]      [30, 2884]       2025-04-10      2025-04-12   \n",
       "4       [791]         [3, 4]      [30, 2884]       2025-04-10      2025-04-12   \n",
       "\n",
       "   current_hours  hours_on_sale  \n",
       "0           48.0            0.0  \n",
       "1           48.0            0.0  \n",
       "2           48.0            0.0  \n",
       "3           48.0            0.0  \n",
       "4           48.0            0.0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data.utils import load_auctions_from_sample\n",
    "\n",
    "data_dir = '../data/sample/'\n",
    "\n",
    "df_auctions = load_auctions_from_sample(data_dir, prediction_time, time_left_mapping, item_to_idx, context_to_idx, bonus_to_idx, modtype_to_idx)\n",
    "\n",
    "print(\"Auctions shape:\", df_auctions.shape)\n",
    "df_auctions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_hours</th>\n",
       "      <th>hours_on_sale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>95700.000000</td>\n",
       "      <td>95700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>18.475914</td>\n",
       "      <td>16.347325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.693010</td>\n",
       "      <td>13.599335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       current_hours  hours_on_sale\n",
       "count   95700.000000   95700.000000\n",
       "mean       18.475914      16.347325\n",
       "std        14.693010      13.599335\n",
       "min         0.000000       0.000000\n",
       "25%         6.000000       5.000000\n",
       "50%        16.000000      12.000000\n",
       "75%        29.000000      25.000000\n",
       "max        48.000000      48.000000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_auctions[['current_hours', 'hours_on_sale']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angel/miniconda3/lib/python3.12/site-packages/lightning/pytorch/utilities/migration/utils.py:56: The loaded checkpoint was produced with Lightning v2.5.1, which is newer than your current Lightning version: v2.5.0.post0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model parameters: 40244801\n",
      "Pre-trained Transformer model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "model = AuctionTransformer.load_from_checkpoint(\n",
    "    '../models/auction_transformer_40M/epoch_epoch=06.ckpt',\n",
    "    map_location=device\n",
    ")\n",
    "\n",
    "print(f'Number of model parameters: {sum(p.numel() for p in model.parameters())}')\n",
    "model.eval()\n",
    "print('Pre-trained Transformer model loaded successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean hours on sale: 17.251306591100477\n",
      "Mean prediction: 17.289504364214775\n",
      "Mean sale probability: 0.27611707089167126\n",
      "Mean absolute error: 3.0645359763677438\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_index</th>\n",
       "      <th>bid</th>\n",
       "      <th>buyout</th>\n",
       "      <th>quantity</th>\n",
       "      <th>time_left</th>\n",
       "      <th>context</th>\n",
       "      <th>bonus_lists</th>\n",
       "      <th>modifier_types</th>\n",
       "      <th>modifier_values</th>\n",
       "      <th>first_appearance</th>\n",
       "      <th>last_appearance</th>\n",
       "      <th>current_hours</th>\n",
       "      <th>hours_on_sale</th>\n",
       "      <th>prediction</th>\n",
       "      <th>sale_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1718619984</td>\n",
       "      <td>6689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6</td>\n",
       "      <td>[791]</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>[30, 1012]</td>\n",
       "      <td>2025-04-10</td>\n",
       "      <td>2025-04-12</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.144670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1718620180</td>\n",
       "      <td>2572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102326.64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>[805]</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>[30, 204]</td>\n",
       "      <td>2025-04-10</td>\n",
       "      <td>2025-04-12</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.144411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1718620212</td>\n",
       "      <td>2154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>594.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20</td>\n",
       "      <td>[789, 397]</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>[74, 2872]</td>\n",
       "      <td>2025-04-10</td>\n",
       "      <td>2025-04-12</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.144491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1718620263</td>\n",
       "      <td>1192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.96</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>[791]</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>[30, 2884]</td>\n",
       "      <td>2025-04-10</td>\n",
       "      <td>2025-04-12</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.143863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1718620305</td>\n",
       "      <td>1170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>312.47</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>[791]</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>[30, 2884]</td>\n",
       "      <td>2025-04-10</td>\n",
       "      <td>2025-04-12</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.144349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  item_index  bid     buyout  quantity  time_left  context  \\\n",
       "0  1718619984        6689  0.0     100.50         1        0.5        6   \n",
       "1  1718620180        2572  0.0  102326.64         1        0.5        2   \n",
       "2  1718620212        2154  0.0     594.57         1        0.5       20   \n",
       "3  1718620263        1192  0.0      44.96         1        0.5        2   \n",
       "4  1718620305        1170  0.0     312.47         1        0.5        2   \n",
       "\n",
       "  bonus_lists modifier_types modifier_values first_appearance last_appearance  \\\n",
       "0       [791]         [3, 4]      [30, 1012]       2025-04-10      2025-04-12   \n",
       "1       [805]         [3, 4]       [30, 204]       2025-04-10      2025-04-12   \n",
       "2  [789, 397]         [3, 4]      [74, 2872]       2025-04-10      2025-04-12   \n",
       "3       [791]         [3, 4]      [30, 2884]       2025-04-10      2025-04-12   \n",
       "4       [791]         [3, 4]      [30, 2884]       2025-04-10      2025-04-12   \n",
       "\n",
       "   current_hours  hours_on_sale  prediction  sale_probability  \n",
       "0           48.0            0.0        0.21          0.144670  \n",
       "1           48.0            0.0        0.26          0.144411  \n",
       "2           48.0            0.0        0.24          0.144491  \n",
       "3           48.0            0.0        0.35          0.143863  \n",
       "4           48.0            0.0        0.27          0.144349  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models.inference import predict_dataframe\n",
    "\n",
    "model = model.to('cuda')\n",
    "df_auctions = predict_dataframe(model, df_auctions, prediction_time, feature_stats)\n",
    "\n",
    "print(\"Mean hours on sale:\", df_auctions['hours_on_sale'].mean())\n",
    "print(\"Mean prediction:\", df_auctions['prediction'].mean())\n",
    "print(\"Mean sale probability:\", df_auctions['sale_probability'].mean())\n",
    "\n",
    "mae = mean_absolute_error(df_auctions['hours_on_sale'], df_auctions['prediction'])\n",
    "print(f\"Mean absolute error: {mae}\")\n",
    "\n",
    "df_auctions.head() # 8.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 9.210261399941912\n"
     ]
    }
   ],
   "source": [
    "df_auctions_12h = df_auctions[df_auctions['current_hours'] <= 0]\n",
    "df_auctions_12h = df_auctions_12h[df_auctions_12h['time_left'] > 12.0]\n",
    "len(df_auctions_12h)\n",
    "\n",
    "mae = mean_absolute_error(df_auctions_12h['hours_on_sale'], df_auctions_12h['prediction'])\n",
    "print(f\"Mean absolute error: {mae}\") # 5.43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auctions_12h[['item_index', 'buyout','quantity', 'time_left', 'current_hours', 'hours_on_sale', 'prediction', 'sale_probability']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe to excel\n",
    "df_auctions_12h.to_excel('../generated/predictions.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "df_auctions_12h['sold_gt'] = df_auctions_12h['hours_on_sale'] <= 6\n",
    "df_auctions_12h['sold_pred'] = df_auctions_12h['sale_probability'] >= 0.7\n",
    "\n",
    "accuracy = accuracy_score(df_auctions_12h['sold_gt'], df_auctions_12h['sold_pred'])\n",
    "precision = precision_score(df_auctions_12h['sold_gt'], df_auctions_12h['sold_pred'])\n",
    "recall = recall_score(df_auctions_12h['sold_gt'], df_auctions_12h['sold_pred'])\n",
    "f1 = f1_score(df_auctions_12h['sold_gt'], df_auctions_12h['sold_pred'])\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'item_index',\n",
    "    'bid',\n",
    "    'buyout',\n",
    "    'quantity',\n",
    "    'time_left',\n",
    "    'first_appearance',\n",
    "    'last_appearance',\n",
    "    'current_hours',\n",
    "    'hours_on_sale',\n",
    "    'prediction',\n",
    "    'sale_probability'\n",
    "]\n",
    "\n",
    "df_error = df_auctions_12h[columns].copy()\n",
    "df_error['error'] = np.abs(df_error['hours_on_sale'] - df_error['prediction'])\n",
    "\n",
    "df_error.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error['time_left'].hist(bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df_error[['hours_on_sale', 'prediction']])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bins for hours_on_sale\n",
    "bins = [(0,12), (12,24), (24,48)]\n",
    "\n",
    "# Calculate mean error for each bin\n",
    "for start, end in bins:\n",
    "    mask = (df_error['hours_on_sale'] >= start) & (df_error['hours_on_sale'] <= end)\n",
    "    mean_error = df_error[mask]['error'].mean()\n",
    "    print(f\"Mean error for hours {start}-{end}: {mean_error:.2f}\")\n",
    "\n",
    "# Create boxplot showing error distribution in each bin\n",
    "error_by_bin = []\n",
    "labels = []\n",
    "for start, end in bins:\n",
    "    mask = (df_error['hours_on_sale'] >= start) & (df_error['hours_on_sale'] <= end)\n",
    "    error_by_bin.append(df_error[mask]['error'])\n",
    "    labels.append(f\"{start}-{end}h\")\n",
    "\n",
    "plt.boxplot(error_by_bin, labels=labels)\n",
    "plt.title(\"Error Distribution by Hours on Sale\")\n",
    "plt.ylabel(\"Absolute Error\")\n",
    "plt.xlabel(\"Hours on Sale Range\") \n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of hours on sale and prediction\n",
    "plt.hist(df_error['hours_on_sale'], bins=100, alpha=0.5, label='Hours on sale')\n",
    "plt.hist(df_error['prediction'], bins=100, alpha=0.5, label='Prediction')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_error['current_hours'], bins=15)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in evaluating the model when the items are recently published, because this will be the main use case for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (df_error['current_hours'] <= 12) & (df_error['time_left'] == 48.0)\n",
    "query_df = df_error[query]\n",
    "print(f\"Mean sale probability: {query_df['sale_probability'].mean()}\")\n",
    "print(f\"Mean error: {query_df['error'].mean()}\")\n",
    "print(f\"Mean hours on sale: {query_df['hours_on_sale'].mean()}\")\n",
    "query_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df['hours_on_sale'].hist(bins=10)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_error[['bid', 'buyout', 'time_left', 'current_hours', 'sale_probability',\n",
    "                        'hours_on_sale', 'prediction', 'error']].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "sns.heatmap(corr_matrix, \n",
    "            annot=True, \n",
    "            cmap='coolwarm',\n",
    "            vmin=-1, vmax=1, \n",
    "            center=0,\n",
    "            fmt='.2f',\n",
    "            square=True) \n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "repo_root = Path.cwd().parent.resolve()\n",
    "sys.path.append(str(repo_root))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.data.auction_dataset import AuctionDataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pd.read_csv('../generated/auction_indices.csv')\n",
    "pairs = pairs[pairs['g_hours_on_sale_max'] < 50]\n",
    "pairs = pairs[pairs['g_current_hours_max'] < 50]\n",
    "\n",
    "train_pairs, val_pairs = train_test_split(pairs, test_size=0.1, random_state=42, shuffle=False)\n",
    "\n",
    "print(f\"Before filtering: {len(train_pairs)}\")\n",
    "\n",
    "train_pairs = train_pairs[train_pairs['g_hours_on_sale_len'] <= 64]\n",
    "val_pairs = val_pairs[val_pairs['g_hours_on_sale_len'] <= 64]\n",
    "\n",
    "print(f\"After filtering: {len(train_pairs)}\\n\")\n",
    "\n",
    "train_pairs = train_pairs[:int(len(train_pairs)*0.85)]\n",
    "\n",
    "print(f\"Train pairs: {len(train_pairs)}\")\n",
    "print(f\"Val pairs: {len(val_pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pairs = val_pairs[val_pairs['record'] == '2025-04-01 00:00:00']\n",
    "val_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "mappings_dir = '../generated/mappings'\n",
    "\n",
    "with open(os.path.join(mappings_dir, 'item_to_idx.json'), 'r') as f:\n",
    "    item_to_idx = json.load(f)\n",
    "\n",
    "with open(os.path.join(mappings_dir, 'context_to_idx.json'), 'r') as f:\n",
    "    context_to_idx = json.load(f)\n",
    "    \n",
    "with open(os.path.join(mappings_dir, 'bonus_to_idx.json'), 'r') as f:\n",
    "    bonus_to_idx = json.load(f)\n",
    "\n",
    "with open(os.path.join(mappings_dir, 'modtype_to_idx.json'), 'r') as f:\n",
    "    modtype_to_idx = json.load(f)\n",
    "\n",
    "feature_stats = torch.load('../generated/feature_stats.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pairs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.auction_transformer import AuctionTransformer\n",
    "\n",
    "model = AuctionTransformer.load_from_checkpoint(\n",
    "    '../models/auction_transformer_40M/last-v1.ckpt',\n",
    "    map_location=device\n",
    ")\n",
    "\n",
    "print(f'Number of model parameters: {sum(p.numel() for p in model.parameters())}')\n",
    "model.eval()\n",
    "print('Pre-trained Transformer model loaded successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.auction_dataset import AuctionDataset\n",
    "from src.data.utils import collate_auctions\n",
    "\n",
    "batch_size = 1024\n",
    "\n",
    "val_dataset = AuctionDataset(val_pairs, feature_stats=feature_stats, path='../generated/sequences.h5')\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_auctions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model on the validation set\n",
    "total_mse = 0\n",
    "total_mae = 0\n",
    "total_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_dataloader):\n",
    "        (auctions, item_index, contexts, bonus_lists, modifier_types, modifier_values, current_hours, time_left, buyout_ranking), y = batch\n",
    "\n",
    "        auctions = auctions.to(device)\n",
    "        item_index = item_index.to(device)\n",
    "        contexts = contexts.to(device)\n",
    "        bonus_lists = bonus_lists.to(device)\n",
    "        modifier_types = modifier_types.to(device)\n",
    "        modifier_values = modifier_values.to(device)\n",
    "        current_hours = current_hours.to(device)\n",
    "        time_left = time_left.to(device)\n",
    "        buyout_ranking = buyout_ranking.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        model.eval()\n",
    "        y_hat = model((auctions, item_index, contexts, bonus_lists, modifier_types, modifier_values, buyout_ranking))\n",
    "\n",
    "        mask = (item_index != 0).float().unsqueeze(-1)\n",
    "        mask = mask * (time_left == 48.0).float().unsqueeze(-1)\n",
    "\n",
    "        current_hours_mask = (current_hours <= 12.0).float().unsqueeze(-1)\n",
    "        mask = mask * current_hours_mask\n",
    "        \n",
    "        mse = torch.nn.functional.mse_loss(y_hat * mask, y.unsqueeze(2) * mask) / mask.sum()\n",
    "        mae = torch.nn.functional.l1_loss(\n",
    "            y_hat * mask * 48.0,\n",
    "            y.unsqueeze(2) * mask * 48.0,\n",
    "            reduction='sum'\n",
    "        ) / mask.sum()\n",
    "        \n",
    "        total_mse += mse.item() * mask.sum()\n",
    "        total_mae += mae.item() * mask.sum()\n",
    "        total_samples += mask.sum()\n",
    "\n",
    "avg_mse = total_mse / total_samples\n",
    "avg_mae = total_mae / total_samples\n",
    "print(f'Validation MSE: {avg_mse}')\n",
    "print(f'Validation MAE: {avg_mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.inference import predict_dataframe\n",
    "\n",
    "predict_dataframe(model, df_auctions[df_auctions['item_index'] == 13815], prediction_time, feature_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
