{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "repo_root = Path.cwd().parent.resolve()\n",
    "sys.path.append(str(repo_root))\n",
    "\n",
    "from src.data.auction_dataset import AuctionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 2248312\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from src.data.utils import collate_auctions\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "pairs = pd.read_csv('../generated/auction_indices.csv')\n",
    "train_pairs, val_pairs = train_test_split(pairs, test_size=0.25, random_state=42, shuffle=False)\n",
    "train_pairs = train_pairs.sample(frac=0.05, random_state=42)\n",
    "\n",
    "train_dataset = AuctionDataset(train_pairs)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_auctions, num_workers=2, pin_memory=True, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4392/4392 [51:20<00:00,  1.43it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([ 8.2451e+00,  8.3870e+00,  1.0000e+00,  3.2520e+01,  1.7332e+01,\n",
       "          1.2983e-02,  1.1338e-02, -1.9910e-03, -9.9918e-03]),\n",
       " tensor([ 2.4380,  2.4546,  0.0000, 18.7104, 13.4391,  0.7069,  0.7071,  0.7034,\n",
       "          0.7107]),\n",
       " tensor(5.7630),\n",
       " tensor(2.3759))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "def compute_feature_stats(train_loader, output_dir='../generated/', max_batches=None):\n",
    "    \"\"\"\n",
    "    Compute means and standard deviations per feature over all valid (non-padded) \n",
    "    timesteps in the training data.\n",
    "    \n",
    "    Assumes that each batch from train_loader is a tuple: (X, y, lengths),\n",
    "    where X has shape (batch_size, max_seq_len, num_features).\n",
    "    \"\"\"\n",
    "    sum_features = None\n",
    "    sum_sq_features = None\n",
    "    total_count = 0\n",
    "    \n",
    "    # For modifier values\n",
    "    modifier_sum = None\n",
    "    modifier_sum_sq = None\n",
    "    modifier_count = 0\n",
    "\n",
    "    for i, batch in enumerate(tqdm(train_loader)):\n",
    "        if max_batches is not None and i >= max_batches:\n",
    "            break\n",
    "            \n",
    "        auctions = batch['auctions']\n",
    "        modifier_values = batch['modifier_values']\n",
    "\n",
    "        # Handle auction features\n",
    "        auction_mask = auctions[:, :, 0] != 0 # padding\n",
    "        auction_mask = auction_mask.unsqueeze(2)  # shape: (B, T, 1)\n",
    "        mask = auction_mask.expand(-1, -1, auctions.size(2))  # shape: (B, T, F)\n",
    "        X_valid = auctions[mask].view(-1, auctions.size(2))  # shape: (total_valid, F)\n",
    "\n",
    "        # Initialize accumulators if this is the first batch\n",
    "        if sum_features is None:\n",
    "            sum_features = X_valid.sum(dim=0)\n",
    "            sum_sq_features = (X_valid ** 2).sum(dim=0)\n",
    "        else:\n",
    "            sum_features += X_valid.sum(dim=0)\n",
    "            sum_sq_features += (X_valid ** 2).sum(dim=0)\n",
    "\n",
    "        total_count += X_valid.size(0)\n",
    "\n",
    "        # Handle modifier values separately\n",
    "        modifier_mask = modifier_values != 0\n",
    "        valid_modifiers = modifier_values[modifier_mask]\n",
    "        \n",
    "        if modifier_sum is None:\n",
    "            modifier_sum = valid_modifiers.sum()\n",
    "            modifier_sum_sq = (valid_modifiers ** 2).sum()\n",
    "        else:\n",
    "            modifier_sum += valid_modifiers.sum()\n",
    "            modifier_sum_sq += (valid_modifiers ** 2).sum()\n",
    "            \n",
    "        modifier_count += valid_modifiers.size(0)\n",
    "\n",
    "    # Compute stats for auction features\n",
    "    means = sum_features / total_count\n",
    "    variances = (sum_sq_features / total_count) - (means ** 2)\n",
    "    stds = torch.sqrt(variances)\n",
    "\n",
    "    # Compute stats for modifier values\n",
    "    modifier_mean = modifier_sum / modifier_count\n",
    "    modifier_variance = (modifier_sum_sq / modifier_count) - (modifier_mean ** 2)\n",
    "    modifier_std = torch.sqrt(modifier_variance)\n",
    "\n",
    "    # Store in pt file\n",
    "    torch.save({\n",
    "        'means': means.cpu(),\n",
    "        'stds': stds.cpu(),\n",
    "        'modifiers_mean': modifier_mean.cpu(),\n",
    "        'modifiers_std': modifier_std.cpu()\n",
    "    }, f'{output_dir}/feature_stats.pt')\n",
    "\n",
    "    return means, stds, modifier_mean, modifier_std\n",
    "\n",
    "compute_feature_stats(train_dataloader, max_batches=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
