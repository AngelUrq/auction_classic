{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3364,
     "status": "ok",
     "timestamp": 1729270089178,
     "user": {
      "displayName": "Ángel Zenteno",
      "userId": "00182779788459853828"
     },
     "user_tz": -120
    },
    "id": "BVwlGTGCcJRb",
    "outputId": "7b71789e-e97c-463f-ec99-87523000df9e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "target_dir = \"../\"\n",
    "zip_file_path = \"generated.zip\"\n",
    "\n",
    "if not os.path.exists(target_dir + 'generated'):\n",
    "    print(f\"The directory {target_dir} does not exist. Proceeding with download.\")\n",
    "\n",
    "    !apt-get update\n",
    "    !apt-get install unzip\n",
    "    \n",
    "    !curl \"https://drive.usercontent.google.com/download?id=10xaugPOoC3SraTwp90sfqSMYQEQK96Ls&confirm=xxx\" -o {zip_file_path}\n",
    "    !mkdir -p {target_dir}\n",
    "    \n",
    "    !unzip {zip_file_path} -d {target_dir}\n",
    "    \n",
    "    print(f\"File downloaded and extracted to {target_dir}\")\n",
    "    \n",
    "    !rm {zip_file_path}\n",
    "else:\n",
    "    print(f\"The directory {target_dir} already exists. No action taken.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8394,
     "status": "ok",
     "timestamp": 1729270097569,
     "user": {
      "displayName": "Ángel Zenteno",
      "userId": "00182779788459853828"
     },
     "user_tz": -120
    },
    "id": "gsqGICHeE47W",
    "outputId": "5fbdf5a0-d09a-40e1-a47a-2a80b8007caa"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "repo_root = Path.cwd().parent.resolve()\n",
    "sys.path.append(str(repo_root))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.data.auction_dataset import AuctionDataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 16985,
     "status": "ok",
     "timestamp": 1729270137493,
     "user": {
      "displayName": "Ángel Zenteno",
      "userId": "00182779788459853828"
     },
     "user_tz": -120
    },
    "id": "KjcQtWtoE47Y",
    "outputId": "12bf3488-0c75-42ff-b77c-f5dc88a524e0"
   },
   "outputs": [],
   "source": [
    "filters = [\n",
    "    (\"g_hours_on_sale_max\", \"<=\", 50),\n",
    "    (\"g_current_hours_max\", \"<=\", 50),\n",
    "    (\"g_hours_on_sale_len\", \"<=\", 64),\n",
    "    (\"record\", \">=\", \"2025-05-01\"),\n",
    "]\n",
    "\n",
    "pairs = pd.read_parquet(\"../generated/auction_indices.parquet\", engine=\"pyarrow\", filters=filters)\n",
    "\n",
    "pairs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_XAyq9XvHHu"
   },
   "source": [
    "## Prepare and balance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Pairs: {len(pairs)}\")\n",
    "\n",
    "split_idx = int(len(pairs) * 0.95)\n",
    "\n",
    "train_pairs = pairs.iloc[:split_idx]\n",
    "train_pairs = train_pairs.iloc[: int(len(train_pairs) * 0.90)]\n",
    "\n",
    "print(f\"Train pairs: {len(train_pairs)}\")\n",
    "\n",
    "val_pairs = pairs.iloc[split_idx:]\n",
    "\n",
    "print(f\"Val pairs: {len(val_pairs)}\")\n",
    "\n",
    "del pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of group_hours_on_sale_mean\n",
    "plt.hist(train_pairs['g_hours_on_sale_mean'], bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pairs.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train_pairs['g_hours_on_sale_len'], bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1729270149598,
     "user": {
      "displayName": "Ángel Zenteno",
      "userId": "00182779788459853828"
     },
     "user_tz": -120
    },
    "id": "oRrffN74vIhi",
    "outputId": "cd8b1691-8251-4840-f6ea-3c14f979c1d5"
   },
   "outputs": [],
   "source": [
    "plt.hist(train_pairs['g_hours_on_sale_mean'], bins=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "mappings_dir = '../generated/mappings'\n",
    "\n",
    "with open(os.path.join(mappings_dir, 'item_to_idx.json'), 'r') as f:\n",
    "    item_to_idx = json.load(f)\n",
    "\n",
    "with open(os.path.join(mappings_dir, 'context_to_idx.json'), 'r') as f:\n",
    "    context_to_idx = json.load(f)\n",
    "    \n",
    "with open(os.path.join(mappings_dir, 'bonus_to_idx.json'), 'r') as f:\n",
    "    bonus_to_idx = json.load(f)\n",
    "\n",
    "with open(os.path.join(mappings_dir, 'modtype_to_idx.json'), 'r') as f:\n",
    "    modtype_to_idx = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_stats = torch.load('../generated/feature_stats.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1729270151907,
     "user": {
      "displayName": "Ángel Zenteno",
      "userId": "00182779788459853828"
     },
     "user_tz": -120
    },
    "id": "-ndNrhFcUmFL",
    "outputId": "6962e361-1b92-4da0-b0f0-58a39cafe50f"
   },
   "outputs": [],
   "source": [
    "from src.data.auction_dataset import AuctionDataset\n",
    "from src.data.utils import collate_auctions\n",
    "\n",
    "batch_size = 1024\n",
    "\n",
    "train_dataset = AuctionDataset(train_pairs, feature_stats=feature_stats, path='../generated/sequences.h5')\n",
    "val_dataset = AuctionDataset(val_pairs, feature_stats=feature_stats, path='../generated/sequences.h5')\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_auctions, num_workers=4, prefetch_factor=8, pin_memory=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_auctions, num_workers=4, prefetch_factor=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FcSVYngOnnZA"
   },
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader = True\n",
    "\n",
    "if test_data_loader:\n",
    "    iter_loader = iter(train_dataloader)\n",
    "    batch = next(iter_loader)\n",
    "    auctions = batch['auctions']\n",
    "    item_index = batch['item_index']\n",
    "    contexts = batch['contexts']\n",
    "    bonus_lists = batch['bonus_lists']\n",
    "    modifier_types = batch['modifier_types']\n",
    "    modifier_values = batch['modifier_values']\n",
    "    current_hours_raw = batch['current_hours_raw']\n",
    "    time_left_raw = batch['time_left_raw']\n",
    "    y = batch['target']\n",
    "\n",
    "    print(f'auctions: {auctions.shape}')\n",
    "    print(f'item_index: {item_index.shape}')\n",
    "    print(f'contexts: {contexts.shape}')\n",
    "    print(f'bonus_lists: {bonus_lists.shape}')\n",
    "    print(f'modifier_types: {modifier_types.shape}')\n",
    "    print(f'modifier_values: {modifier_values.shape}')\n",
    "    print(f'y: {y.shape}')\n",
    "    \n",
    "    print(\"\\nAuction feature statistics:\")\n",
    "    for i in range(auctions.shape[-1]):\n",
    "        mean = auctions[..., i].mean().item()\n",
    "        std = auctions[..., i].std().item()\n",
    "        print(f\"Feature {i}: mean = {mean:.3f}, std = {std:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.auction_transformer import AuctionTransformer\n",
    "\n",
    "input_size = 9\n",
    "embedding_dim = 32\n",
    "d_model = 256\n",
    "dim_feedforward = d_model * 4\n",
    "nhead = 16\n",
    "num_layers = 4\n",
    "dropout_p = 0.0\n",
    "n_items = len(item_to_idx)\n",
    "n_contexts = len(context_to_idx) + 1\n",
    "n_bonuses = len(bonus_to_idx)\n",
    "n_modtypes = len(modtype_to_idx)\n",
    "\n",
    "model = AuctionTransformer(\n",
    "    input_size, \n",
    "    n_items, \n",
    "    n_contexts,\n",
    "    n_bonuses,\n",
    "    n_modtypes,\n",
    "    embedding_dim, \n",
    "    d_model, \n",
    "    dim_feedforward, \n",
    "    nhead, \n",
    "    num_layers,\n",
    "    dropout_p=dropout_p,\n",
    "    learning_rate=1e-4,\n",
    "    logging_interval=1000,\n",
    "    quantiles=[0.1, 0.5, 0.9],\n",
    "    log_raw_batch_data=True,\n",
    "    log_step_predictions=True,\n",
    ")\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GyMw3icYnqXo"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TuGhUuNIE47a",
    "outputId": "d7db1411-1ad4-4954-ba1a-094c09c0ce0b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.profilers import PyTorchProfiler\n",
    "from torch.profiler import schedule, tensorboard_trace_handler\n",
    "\n",
    "\n",
    "!rm -rf ../generated/logs\n",
    "\n",
    "name = 'auction-transformer-40M-quantile'\n",
    "\n",
    "logger = WandbLogger(\n",
    "    project=\"auction_transformer\",\n",
    "    name=name\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f'../models/{name}',\n",
    "    filename='epoch_{epoch:02d}',\n",
    "    save_top_k=-1,\n",
    "    every_n_epochs=1,\n",
    "    save_last=True\n",
    ")\n",
    "\"\"\"\n",
    "profiler = PyTorchProfiler(\n",
    "    dirpath=\"profiler_logs\",              # where traces go\n",
    "    filename=\"profile\",                   # base name per rank\n",
    "    record_shapes=True,\n",
    "    profile_memory=True,\n",
    "    with_stack=True,\n",
    "    on_trace_ready=tensorboard_trace_handler(\"profiler_logs\"),\n",
    "    schedule=schedule(wait=1, warmup=1, active=3, repeat=2),\n",
    ")\"\"\"\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=2,\n",
    "    accelerator='gpu',\n",
    "    devices=1,\n",
    "    log_every_n_steps=10,\n",
    "    logger=logger,\n",
    "    limit_val_batches=500,\n",
    "    val_check_interval=0.1,\n",
    "    precision=\"bf16\",\n",
    "    callbacks=[checkpoint_callback],\n",
    "    gradient_clip_val=3.0,\n",
    "    #profiler=profiler,\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
