{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pd.read_csv('auction_indices.csv')\n",
    "pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_pairs, val_pairs = train_test_split(pairs, test_size=0.1, random_state=42, shuffle=False)\n",
    "\n",
    "val_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv('items.csv')\n",
    "n_items = len(items)\n",
    "\n",
    "item_to_index = {item_id: i + 1 for i, item_id in enumerate(items['item_id'])}\n",
    "item_to_index[0] = 0\n",
    "n_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuctionDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, pairs, item_to_index, path='data'):\n",
    "        self.pairs = pairs\n",
    "        self.time_left_to_int = {\n",
    "            'VERY_LONG': 48,\n",
    "            'LONG': 24,\n",
    "            'MEDIUM': 12,\n",
    "            'SHORT': 2\n",
    "        }\n",
    "        self.column_map = {\n",
    "            'bid': 0,\n",
    "            'buyout': 1,\n",
    "            'quantity': 2,\n",
    "            'item_id': 3,\n",
    "            'time_left': 4,\n",
    "            'hours_since_first_appearance': 5\n",
    "        }\n",
    "        self.item_to_index = item_to_index\n",
    "        self.path = path\n",
    "        \n",
    "        print(f\"Dataset size: {len(self)}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def scale(self, column):\n",
    "        q1, median, q3 = torch.quantile(column, torch.tensor([0.25, 0.5, 0.75]), dim=0)\n",
    "        iqr = q3 - q1\n",
    "        \n",
    "        if iqr < 1e-3:\n",
    "            if len(column) == 1:\n",
    "                return 0.0\n",
    "            return (column - torch.mean(column)) / (torch.std(column) + 1e-6)\n",
    "        else:\n",
    "            return (column - median) / (q3 - q1 + 1e-6)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pair = self.pairs.iloc[idx]\n",
    "        \n",
    "        record = pair['record']\n",
    "        item_id = pair['item_id']\n",
    "        \n",
    "        date_time_obj = datetime.strptime(record, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        date_folder_name = date_time_obj.strftime(\"%d-%m-%Y\")\n",
    "        hour_folder_name = date_time_obj.strftime(\"%H\")\n",
    "        \n",
    "        X = torch.load(f'{self.path}/{date_folder_name}/{hour_folder_name}/{item_id}.pt')\n",
    "        \n",
    "        y = X[:, -1]\n",
    "        X = X[:, :-1]\n",
    "        \n",
    "        X[:, self.column_map['bid']] = X[:, self.column_map['bid']] * 10000\n",
    "        X[:, self.column_map['buyout']] = X[:, self.column_map['buyout']] * 10000\n",
    "        X[:, self.column_map['item_id']] = torch.tensor([self.item_to_index.get(item, 0) for item in X[:, self.column_map['item_id']]], dtype=torch.long)\n",
    "        X[:, self.column_map['time_left']] = X[:, self.column_map['time_left']] / 48.0\n",
    "        X[:, self.column_map['hours_since_first_appearance']] = X[:, self.column_map['hours_since_first_appearance']] / 48.0\n",
    "        \n",
    "        X[:, self.column_map['bid']] = self.scale(X[:, self.column_map['bid']])\n",
    "        X[:, self.column_map['buyout']] = self.scale(X[:, self.column_map['buyout']])\n",
    "        X[:, self.column_map['quantity']] = X[:, self.column_map['quantity']] / 200.0\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_auctions(batch):\n",
    "    X, y = zip(*batch)\n",
    "    \n",
    "    max_length = max([x.size(0) for x in X])\n",
    "    \n",
    "    X = [F.pad(x, (0, 0, 0, max_length - x.size(0))) for x in X]\n",
    "    y = [F.pad(x, (0, max_length - x.size(0))) for x in y]\n",
    "    \n",
    "    X = torch.stack(X)\n",
    "    y = torch.stack(y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "train_dataset = AuctionDataset(pairs, item_to_index)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_auctions)\n",
    "\n",
    "iter_loader = iter(train_loader)\n",
    "X, y = next(iter_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size=5, item_index=3, embedding_size=16, hidden_size=16, dropout_p=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.item_index = item_index\n",
    "        n_items = len(item_to_index)\n",
    "\n",
    "        self.embedding = nn.Embedding(n_items, embedding_size)\n",
    "        self.rnn = nn.LSTM(input_size + embedding_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, X):\n",
    "        item_ids = X[:, :, self.item_index].long()\n",
    "        \n",
    "        X = torch.cat([X[:, :, :self.item_index], X[:, :, self.item_index + 1:]], dim=2)\n",
    "        \n",
    "        item_embeddings = self.dropout(self.embedding(item_ids))\n",
    "        \n",
    "        X = torch.cat([X, item_embeddings], dim=2)\n",
    "        \n",
    "        output, (hidden, cell) = self.rnn(X)\n",
    "        \n",
    "        return output, (hidden, cell)\n",
    "    \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, encoder_outputs, encoder_hidden):\n",
    "        output, _ = self.rnn(encoder_outputs, encoder_hidden)\n",
    "        output = self.projection(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    \n",
    "class AuctionPredictor(nn.Module):\n",
    "    def __init__(self, input_size=5, encoder_hidden_size=16, decoder_hidden_size=16, item_index=3, embedding_size=16, dropout_p=0.1):\n",
    "        super(AuctionPredictor, self).__init__()\n",
    "        self.encoder = Encoder(input_size, item_index, embedding_size, encoder_hidden_size, dropout_p)\n",
    "        self.decoder = Decoder(encoder_hidden_size, decoder_hidden_size)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        encoder_outputs, encoder_hidden = self.encoder(X)\n",
    "        decoder_outputs = self.decoder(encoder_outputs, encoder_hidden)\n",
    "        return decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 16\n",
    "encoder_hidden_size = 32\n",
    "decoder_hidden_size = 32\n",
    "epochs = 1\n",
    "\n",
    "train_dataset = AuctionDataset(pairs, item_to_index)\n",
    "val_dataset = AuctionDataset(val_pairs, item_to_index)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, collate_fn=collate_auctions)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=128, shuffle=True, collate_fn=collate_auctions)\n",
    "\n",
    "model = AuctionPredictor(input_size=5, encoder_hidden_size=encoder_hidden_size, decoder_hidden_size=decoder_hidden_size, item_index=3, embedding_size=embedding_size).to(device)\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "criterion = nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, checkpoint_path='checkpoints'):\n",
    "    os.makedirs(checkpoint_path, exist_ok=True)\n",
    "    checkpoint_file = os.path.join(checkpoint_path, f\"checkpoint_epoch_{epoch}.pt\")\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }, checkpoint_file)\n",
    "    print(f\"Checkpoint saved at {checkpoint_file}\")\n",
    "\n",
    "def train(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    epochs,\n",
    "    eval_steps,\n",
    "    device,\n",
    "    optimizer,\n",
    "    criterion\n",
    "):\n",
    "    print(\"Starting training for\", epochs, \"epochs\")\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        \n",
    "        mse_losses = []\n",
    "        mae_losses = []\n",
    "        \n",
    "        for i, (X, y) in enumerate(train_loader):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            y_pred = model(X)\n",
    "            \n",
    "            loss = criterion(y_pred, y.unsqueeze(2))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                mae = F.l1_loss(y_pred, y.unsqueeze(2), reduction='sum')\n",
    "                n = (y != 0).sum().item()\n",
    "                mae /= n\n",
    "                \n",
    "            mae_losses.append(mae.item())\n",
    "            mse_losses.append(loss.item())\n",
    "            \n",
    "            if i % 50 == 0:\n",
    "                print(f\"Epoch {epoch} Iteration {i} Loss {np.mean(mse_losses)} MAE {np.mean(mae_losses)}\")\n",
    "                mse_losses = []\n",
    "                mae_losses = []\n",
    "                \n",
    "            if i % eval_steps == 0:\n",
    "                evaluate(model, val_loader, device, criterion)\n",
    "        \n",
    "        if epoch  % 5 == 0:\n",
    "            save_checkpoint(model, optimizer, epoch)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(\n",
    "    model,\n",
    "    val_loader,\n",
    "    device,\n",
    "    criterion\n",
    "):\n",
    "    print(\"Evaluating model\")\n",
    "    model.eval()\n",
    "\n",
    "    mse_losses = []\n",
    "    mae_losses = []\n",
    "\n",
    "    for i, (X, y) in enumerate(val_loader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        y_pred = model(X)\n",
    "\n",
    "        loss = criterion(y_pred, y.unsqueeze(2))\n",
    "        \n",
    "        mae = F.l1_loss(y_pred, y.unsqueeze(2), reduction='sum')\n",
    "        n = (y != 0).sum().item()\n",
    "        mae /= n\n",
    "        \n",
    "        mse_losses.append(loss.item())\n",
    "        mae_losses.append(mae.item())\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            break\n",
    "        \n",
    "    print(f\"Validation loss: {np.mean(mse_losses)} MAE: {np.mean(mae_losses)}\")\n",
    "    model.train()\n",
    "    \n",
    "train(\n",
    "    model,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    epochs,\n",
    "    eval_steps=300,\n",
    "    device=device,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
